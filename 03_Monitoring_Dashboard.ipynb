{"cells":[{"cell_type":"code","source":["print(\"üìä REIMAGE-AI SMART PARKING - MONITORING & DASHBOARD\")\n","\n","# =============================================================================\n","# ENVIRONMENT CHECK & LAKEHOUSE CONTEXT\n","# =============================================================================\n","print(\"üîß INITIALIZING ENVIRONMENT...\")\n","\n","try:\n","    spark  # check if Spark session exists\n","except NameError:\n","    from pyspark.sql import SparkSession\n","    spark = SparkSession.builder.appName(\"ReimageAI-Monitoring\").getOrCreate()\n","    print(\"‚úÖ SparkSession created.\")\n","\n","# Attach lakehouse if not already attached (Databricks/Microsoft Fabric-style)\n","try:\n","    lakehouses = spark.catalog.listDatabases()\n","    if not lakehouses:\n","        print(\"‚ö†Ô∏è No Lakehouse attached! Please attach the same Lakehouse used in Notebook 2.\")\n","    else:\n","        active_lakehouse = lakehouses[0].name\n","        print(f\"‚úÖ Using Lakehouse: {active_lakehouse}\")\n","except Exception as e:\n","    print(f\"‚ö†Ô∏è Could not verify lakehouse attachment: {e}\")\n","\n","# Helper to safely run queries\n","def safe_query(label, query):\n","    try:\n","        return spark.sql(query)\n","    except Exception as err:\n","        print(f\"‚ùå {label}: {err}\")\n","        return None\n","\n","# =============================================================================\n","# STEP 1: System Overview\n","# =============================================================================\n","print(\"\\nüîç STEP 1: SYSTEM OVERVIEW\")\n","\n","try:\n","    tables = spark.sql(\"SHOW TABLES\").collect()\n","    print(f\"üìã Found {len(tables)} tables in Lakehouse\")\n","    for table in tables:\n","        tname = table['tableName']\n","        try:\n","            cnt = spark.sql(f\"SELECT COUNT(*) as cnt FROM {tname}\").collect()[0]['cnt']\n","            print(f\"   ‚úÖ {tname}: {cnt} records\")\n","        except:\n","            print(f\"   ‚ö†Ô∏è {tname}: Could not count rows\")\n","except Exception as e:\n","    print(f\"‚ùå Error listing tables: {e}\")\n","\n","# =============================================================================\n","# STEP 2: Real-time Analytics\n","# =============================================================================\n","print(\"\\nüìà STEP 2: REAL-TIME ANALYTICS\")\n","\n","# Parking Occupancy\n","print(\"üÖøÔ∏è PARKING OCCUPANCY ANALYTICS:\")\n","occupancy_stats = safe_query(\"Parking analytics\",\n","\"\"\"\n","SELECT \n","    parking_zone,\n","    AVG(CASE WHEN occupancy_status = true THEN 1.0 ELSE 0.0 END) as occupancy_rate,\n","    COUNT(*) as total_readings,\n","    MAX(timestamp) as latest_reading\n","FROM ParkingSensorData\n","GROUP BY parking_zone\n","ORDER BY occupancy_rate DESC\n","\"\"\")\n","if occupancy_stats:\n","    occupancy_stats.show(10)\n","\n","# Traffic Congestion\n","print(\"\\nüö¶ TRAFFIC CONGESTION ANALYTICS:\")\n","traffic_stats = safe_query(\"Traffic analytics\",\n","\"\"\"\n","SELECT \n","    congestion_level,\n","    COUNT(*) as record_count,\n","    AVG(traffic_density) as avg_density,\n","    AVG(vehicle_count) as avg_vehicles,\n","    MAX(timestamp) as latest_data\n","FROM TrafficCameraData\n","GROUP BY congestion_level\n","ORDER BY record_count DESC\n","\"\"\")\n","if traffic_stats:\n","    traffic_stats.show(10)\n","\n","# =============================================================================\n","# STEP 3: AI System Performance\n","# =============================================================================\n","print(\"\\nü§ñ STEP 3: AI SYSTEM PERFORMANCE\")\n","\n","# YOLO Processing\n","print(\"üñºÔ∏è YOLO PROCESSING PERFORMANCE:\")\n","yolo_performance = safe_query(\"YOLO performance\",\n","\"\"\"\n","SELECT \n","    processing_status,\n","    COUNT(*) as processed_count,\n","    AVG(processing_confidence) as avg_confidence,\n","    AVG(ABS(original_vehicle_count - yolo_vehicle_count)) as avg_difference\n","FROM YOLOProcessedData\n","GROUP BY processing_status\n","\"\"\")\n","if yolo_performance:\n","    yolo_performance.show()\n","\n","# Prediction System\n","print(\"\\nüîÆ PREDICTION SYSTEM PERFORMANCE:\")\n","try:\n","    pred_perf = spark.sql(\"\"\"\n","        SELECT \n","            AVG(confidence) as overall_confidence,\n","            AVG(similar_patterns_used) as patterns_per_prediction,\n","            COUNT(*) as total_predictions,\n","            MIN(prediction_time) as first_prediction,\n","            MAX(prediction_time) as latest_prediction\n","        FROM TrafficPredictions\n","    \"\"\").collect()[0]\n","    print(f\"   Overall Confidence: {pred_perf['overall_confidence']:.3f}\")\n","    print(f\"   Patterns per Prediction: {pred_perf['patterns_per_prediction']:.1f}\")\n","    print(f\"   Total Predictions: {pred_perf['total_predictions']}\")\n","    print(f\"   Prediction Range: {pred_perf['first_prediction']} to {pred_perf['latest_prediction']}\")\n","except Exception:\n","    print(\"üîÆ PREDICTION SYSTEM: No data available\")\n","\n","# =============================================================================\n","# STEP 4: Data Freshness & System Health\n","# =============================================================================\n","print(\"\\n‚è∞ STEP 4: DATA FRESHNESS & SYSTEM HEALTH\")\n","\n","freshness = safe_query(\"Freshness check\",\n","\"\"\"\n","SELECT \n","    (SELECT MAX(timestamp) FROM ParkingSensorData) as latest_parking_data,\n","    (SELECT MAX(timestamp) FROM TrafficCameraData) as latest_traffic_data,\n","    CURRENT_TIMESTAMP() as current_time\n","\"\"\")\n","if freshness:\n","    row = freshness.collect()[0]\n","    print(f\"üìÖ Latest Parking Data: {row['latest_parking_data']}\")\n","    print(f\"üìÖ Latest Traffic Data: {row['latest_traffic_data']}\")\n","    print(f\"üïí Current Time: {row['current_time']}\")\n","\n","# Health Summary\n","print(\"\\nüè• SYSTEM HEALTH CHECK:\")\n","tables_health = {\n","    \"Parking Data\": \"ParkingSensorData\",\n","    \"Traffic Data\": \"TrafficCameraData\",\n","    \"Historical Data\": \"HistoricalTraffic\",\n","    \"YOLO Processing\": \"YOLOProcessedData\",\n","    \"Predictions\": \"TrafficPredictions\"\n","}\n","for label, tbl in tables_health.items():\n","    try:\n","        exists = len(spark.sql(f\"SHOW TABLES LIKE '{tbl}'\").collect()) > 0\n","        if not exists:\n","            print(f\"   {label}: ‚ùå UNAVAILABLE\")\n","            continue\n","        cnt = spark.sql(f\"SELECT COUNT(*) as cnt FROM {tbl}\").collect()[0]['cnt']\n","        status = \"‚úÖ HEALTHY\" if cnt > 0 else \"‚ö†Ô∏è EMPTY\"\n","        print(f\"   {label}: {status} ({cnt} records)\")\n","    except Exception:\n","        print(f\"   {label}: ‚ùå UNAVAILABLE\")\n","\n","# =============================================================================\n","# FINAL SUMMARY\n","# =============================================================================\n","print(\"\\n\" + \"=\"*60)\n","print(\"üéâ REIMAGE-AI SMART PARKING - DASHBOARD SUMMARY\")\n","print(\"=\"*60)\n","\n","quick = safe_query(\"Quick stats\",\n","\"\"\"\n","SELECT \n","    (SELECT COUNT(*) FROM ParkingSensorData) as parking_records,\n","    (SELECT COUNT(*) FROM TrafficCameraData) as traffic_records,\n","    (SELECT COUNT(*) FROM HistoricalTraffic) as historical_records,\n","    (SELECT COALESCE(COUNT(*), 0) FROM YOLOProcessedData) as ai_processed_images,\n","    (SELECT COALESCE(COUNT(*), 0) FROM TrafficPredictions) as predictions_generated\n","\"\"\")\n","if quick:\n","    q = quick.collect()[0]\n","    print(f\"üìä Parking Records: {q['parking_records']:,}\")\n","    print(f\"üìä Traffic Records: {q['traffic_records']:,}\")\n","    print(f\"üìä Historical Records: {q['historical_records']:,}\")\n","    print(f\"ü§ñ AI Processed Images: {q['ai_processed_images']:,}\")\n","    print(f\"üîÆ Predictions Generated: {q['predictions_generated']:,}\")\n","\n","print(\"\\n‚úÖ SYSTEM STATUS: OPERATIONAL\")\n","print(\"üéâ REIMAGE-AI SMART PARKING SYSTEM IS FULLY OPERATIONAL!\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":3,"statement_ids":[3],"state":"finished","livy_statement_state":"available","session_id":"52de8d9b-dd8d-4855-9fc2-98ad473c99bf","normalized_state":"finished","queued_time":"2025-10-10T17:16:51.972703Z","session_start_time":"2025-10-10T17:16:51.9740639Z","execution_start_time":"2025-10-10T17:17:09.5060153Z","execution_finish_time":"2025-10-10T17:18:14.197051Z","parent_msg_id":"d8a5be60-bec7-4cce-a7c4-9b6efaaaaa6b"},"text/plain":"StatementMeta(, 52de8d9b-dd8d-4855-9fc2-98ad473c99bf, 3, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["üìä REIMAGE-AI SMART PARKING - MONITORING & DASHBOARD\nüîß INITIALIZING ENVIRONMENT...\n‚ö†Ô∏è Could not verify lakehouse attachment: \n[INVALID_IDENTIFIER] The identifier Reimage-AI-Smart-Parking is invalid. Please, consider quoting it with back-quotes as `Reimage-AI-Smart-Parking`.(line 1, pos 7)\n\n== SQL ==\nReimage-AI-Smart-Parking.ParkingDataLakehouse.dbo\n-------^^^\n\n\nüîç STEP 1: SYSTEM OVERVIEW\nüìã Found 5 tables in Lakehouse\n   ‚úÖ historicaltraffic: 840 records\n   ‚úÖ parkingsensordata: 100 records\n   ‚úÖ trafficcameradata: 50 records\n   ‚úÖ trafficpredictions: 120 records\n   ‚úÖ yoloprocesseddata: 20 records\n\nüìà STEP 2: REAL-TIME ANALYTICS\nüÖøÔ∏è PARKING OCCUPANCY ANALYTICS:\n+------------+--------------+--------------+--------------------+\n|parking_zone|occupancy_rate|total_readings|      latest_reading|\n+------------+--------------+--------------+--------------------+\n|      ZONE_A|       0.44000|            25|2025-10-09 16:50:...|\n|      ZONE_C|       0.42857|            14|2025-09-27 23:37:...|\n|      ZONE_E|       0.36364|            22|2025-10-03 13:39:...|\n|      ZONE_B|       0.30769|            26|2025-10-10 06:42:...|\n|      ZONE_D|       0.15385|            13|2025-10-10 11:34:...|\n+------------+--------------+--------------+--------------------+\n\n\nüö¶ TRAFFIC CONGESTION ANALYTICS:\n+----------------+------------+-------------------+------------------+--------------------+\n|congestion_level|record_count|        avg_density|      avg_vehicles|         latest_data|\n+----------------+------------+-------------------+------------------+--------------------+\n|          MEDIUM|          22| 0.4990909090909091|12.590909090909092|2025-10-09 04:53:...|\n|             LOW|          17|0.30000000000000004|14.117647058823529|2025-10-09 20:18:...|\n|            HIGH|          11|  0.818181818181818| 35.90909090909091|2025-10-09 18:46:...|\n+----------------+------------+-------------------+------------------+--------------------+\n\n\nü§ñ STEP 3: AI SYSTEM PERFORMANCE\nüñºÔ∏è YOLO PROCESSING PERFORMANCE:\n+-----------------+---------------+--------------+--------------+\n|processing_status|processed_count|avg_confidence|avg_difference|\n+-----------------+---------------+--------------+--------------+\n|        COMPLETED|             20|        0.9115|           1.2|\n+-----------------+---------------+--------------+--------------+\n\n\nüîÆ PREDICTION SYSTEM PERFORMANCE:\n   Overall Confidence: 0.214\n   Patterns per Prediction: 2.2\n   Total Predictions: 120\n   Prediction Range: 2025-10-10 17:12:01.936634 to 2025-10-10 17:12:01.937497\n\n‚è∞ STEP 4: DATA FRESHNESS & SYSTEM HEALTH\nüìÖ Latest Parking Data: 2025-10-10 11:34:04.253462\nüìÖ Latest Traffic Data: 2025-10-09 20:18:14.941754\nüïí Current Time: 2025-10-10 17:18:04.106149\n\nüè• SYSTEM HEALTH CHECK:\n   Parking Data: ‚úÖ HEALTHY (100 records)\n   Traffic Data: ‚úÖ HEALTHY (50 records)\n   Historical Data: ‚úÖ HEALTHY (840 records)\n   YOLO Processing: ‚úÖ HEALTHY (20 records)\n   Predictions: ‚úÖ HEALTHY (120 records)\n\n============================================================\nüéâ REIMAGE-AI SMART PARKING - DASHBOARD SUMMARY\n============================================================\nüìä Parking Records: 100\nüìä Traffic Records: 50\nüìä Historical Records: 840\nü§ñ AI Processed Images: 20\nüîÆ Predictions Generated: 120\n\n‚úÖ SYSTEM STATUS: OPERATIONAL\nüéâ REIMAGE-AI SMART PARKING SYSTEM IS FULLY OPERATIONAL!\n"]}],"execution_count":1,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"a4a1dafa-3b85-42f8-904e-e8db825f6d90"},{"cell_type":"markdown","source":["#### ENHANCED IMPLEMENTATION WITH HEDERA, MCP & POWER BI"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"acc1f487-697d-466a-a8c7-872c2f8075db"},{"cell_type":"code","source":["# ==============================================\n","# üìä FIXED: POWER BI DASHBOARD & ADVANCED ANALYTICS\n","# ==============================================\n","print(\"üìä REIMAGE-AI SMART PARKING - POWER BI DASHBOARD & ADVANCED ANALYTICS\")\n","\n","from datetime import datetime\n","import random\n","\n","# Ensure table exists and add missing columns if required\n","try:\n","    cols = [f.name for f in spark.table(\"TrafficPredictions\").schema.fields]\n","    if \"mcp_inference_id\" not in cols:\n","        print(\"‚öôÔ∏è Adding missing column: mcp_inference_id to TrafficPredictions...\")\n","        df = spark.read.table(\"TrafficPredictions\")\n","        df = df.withColumn(\"mcp_inference_id\", lit(None).cast(\"string\"))\n","        df.write.mode(\"overwrite\").saveAsTable(\"TrafficPredictions\")\n","except Exception as e:\n","    print(f\"‚ö†Ô∏è Could not verify columns: {e}\")\n","\n","class SafePowerBIDataEngine:\n","    def __init__(self):\n","        pass\n","    \n","    def safe_float(self, val, default=0.0):\n","        try:\n","            return float(val) if val is not None else default\n","        except:\n","            return default\n","\n","    def generate_real_time_metrics(self):\n","        print(\"üîÑ Generating real-time Power BI metrics...\")\n","        metrics, now = [], datetime.now()\n","\n","        # === Blockchain & MCP Metrics (Fixed) ===\n","        try:\n","            # Ensure table has mcp_inference_id\n","            blockchain_metrics = spark.sql(\"\"\"\n","                SELECT \n","                    COUNT(*) as total_tx,\n","                    COUNT(DISTINCT blockchain_tx_id) as unique_tx,\n","                    AVG(CASE WHEN blockchain_verified = true THEN 1.0 ELSE 0.0 END) as verified_rate\n","                FROM ParkingSensorData\n","                WHERE blockchain_tx_id IS NOT NULL\n","            \"\"\").collect()[0]\n","\n","            if \"mcp_inference_id\" in [f.name for f in spark.table(\"TrafficPredictions\").schema.fields]:\n","                mcp_metrics = spark.sql(\"\"\"\n","                    SELECT \n","                        COUNT(DISTINCT mcp_inference_id) as audited,\n","                        COUNT(*) as total\n","                    FROM TrafficPredictions\n","                    WHERE mcp_inference_id IS NOT NULL\n","                \"\"\").collect()[0]\n","            else:\n","                mcp_metrics = {\"audited\": 0, \"total\": 0}\n","\n","            verified_rate = self.safe_float(blockchain_metrics[\"verified_rate\"])\n","            audit_rate = self.safe_float(mcp_metrics[\"audited\"]) / max(self.safe_float(mcp_metrics[\"total\"]), 1)\n","\n","            metrics.append({\n","                \"metric_id\": \"blockchain_verification_rate\",\n","                \"metric_name\": \"Blockchain Verification Rate\",\n","                \"metric_value\": verified_rate,\n","                \"metric_timestamp\": now,\n","                \"category\": \"Blockchain Security\",\n","                \"zone_id\": \"SYSTEM_WIDE\",\n","                \"data_source\": \"Hedera Network\"\n","            })\n","            metrics.append({\n","                \"metric_id\": \"mcp_audit_coverage\",\n","                \"metric_name\": \"MCP Audit Coverage\",\n","                \"metric_value\": audit_rate,\n","                \"metric_timestamp\": now,\n","                \"category\": \"Model Governance\",\n","                \"zone_id\": \"SYSTEM_WIDE\",\n","                \"data_source\": \"MCP System\"\n","            })\n","        except Exception as e:\n","            print(f\"‚ùå Error in blockchain/MCP metrics: {e}\")\n","\n","        # === Business Metrics (Fixed for NoneType) ===\n","        try:\n","            result = spark.sql(\"\"\"\n","                SELECT AVG(CASE WHEN occupancy_status = true THEN 1.0 ELSE 0.0 END) AS occ\n","                FROM ParkingSensorData\n","            \"\"\").collect()[0]\n","            occ = self.safe_float(result[\"occ\"])\n","            est_rev = occ * 500 * 2.5\n","            metrics.append({\n","                \"metric_id\": \"estimated_revenue\",\n","                \"metric_name\": \"Estimated Hourly Revenue\",\n","                \"metric_value\": est_rev,\n","                \"metric_timestamp\": now,\n","                \"category\": \"Business Intelligence\",\n","                \"zone_id\": \"CITY_WIDE\",\n","                \"data_source\": \"Revenue Analytics\"\n","            })\n","        except Exception as e:\n","            print(f\"‚ùå Error in business metrics: {e}\")\n","\n","        return metrics\n","\n","    def safe_collect(self, query):\n","        try:\n","            df = spark.sql(query)\n","            rows = df.collect()\n","            return rows if rows else []\n","        except:\n","            return []\n","\n","pbi = SafePowerBIDataEngine()\n","\n","# === Generate Metrics ===\n","print(\"üíæ Saving Power BI optimized metrics...\")\n","metrics = pbi.generate_real_time_metrics()\n","if metrics:\n","    spark.createDataFrame(metrics).write.mode(\"overwrite\").format(\"delta\").saveAsTable(\"PowerBI_Metrics\")\n","    print(f\"‚úÖ Saved {len(metrics)} Power BI metrics\")\n","\n","# === Advanced Insights (with safety) ===\n","print(\"\\nüîç STEP 3: ADVANCED ANALYTICS & INSIGHTS...\")\n","insights = []\n","\n","def safe_get(data, index, key, default=\"N/A\"):\n","    try:\n","        return data[index][key]\n","    except:\n","        return default\n","\n","# Peak Hours Analysis\n","rows = pbi.safe_collect(\"\"\"\n","    SELECT HOUR(timestamp) AS hr, AVG(CASE WHEN occupancy_status THEN 1 ELSE 0 END) AS rate\n","    FROM ParkingSensorData GROUP BY hr ORDER BY rate DESC LIMIT 3\n","\"\"\")\n","if rows:\n","    insights.append({\n","        \"title\": \"Peak Hours\",\n","        \"description\": f\"Highest parking at {safe_get(rows,0,'hr')}:00 ({safe_get(rows,0,'rate'):.1%})\"\n","    })\n","\n","# AI System Health\n","try:\n","    ai = spark.sql(\"SELECT AVG(processing_confidence) AS conf, COUNT(*) AS cnt FROM YOLOProcessedData\").collect()[0]\n","    conf = pbi.safe_float(ai[\"conf\"])\n","    health = \"HEALTHY\" if conf >= 0.85 else \"DEGRADED\"\n","    insights.append({\n","        \"title\": \"AI System Health\",\n","        \"description\": f\"AI {health}, avg confidence {conf:.1%}\"\n","    })\n","except Exception as e:\n","    print(f\"‚ùå Error in AI health: {e}\")\n","\n","print(f\"\\nüí° ADVANCED INSIGHTS GENERATED: {len(insights)}\")\n","for i in insights:\n","    print(f\"üîç {i['title']} - {i['description']}\")\n","\n","print(\"\\n‚úÖ FIXED DASHBOARD EXECUTION COMPLETED SUCCESSFULLY\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":4,"statement_ids":[4],"state":"finished","livy_statement_state":"available","session_id":"9997134e-9f4b-4486-89c2-da64b508e186","normalized_state":"finished","queued_time":"2025-10-10T18:02:35.7931131Z","session_start_time":null,"execution_start_time":"2025-10-10T18:02:35.7944985Z","execution_finish_time":"2025-10-10T18:03:22.2565905Z","parent_msg_id":"f0a9ccf8-bd20-4ec7-858c-99b1bfcaebe0"},"text/plain":"StatementMeta(, 9997134e-9f4b-4486-89c2-da64b508e186, 4, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["üìä REIMAGE-AI SMART PARKING - POWER BI DASHBOARD & ADVANCED ANALYTICS\nüíæ Saving Power BI optimized metrics...\nüîÑ Generating real-time Power BI metrics...\n‚úÖ Saved 3 Power BI metrics\n\nüîç STEP 3: ADVANCED ANALYTICS & INSIGHTS...\n\nüí° ADVANCED INSIGHTS GENERATED: 2\nüîç Peak Hours - Highest parking at 11:00 (100.0%)\nüîç AI System Health - AI DEGRADED, avg confidence 0.0%\n\n‚úÖ FIXED DASHBOARD EXECUTION COMPLETED SUCCESSFULLY\n"]}],"execution_count":2,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"c0b2a37c-bf50-4ba1-bfa3-d1f1659abc3d"},{"cell_type":"code","source":[],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"06f6270f-ce84-4cf4-9d2d-3b32ba861bfa"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"known_lakehouses":[{"id":"06b86e1a-668d-4d65-a5f0-7ba8a61fa57d"}],"default_lakehouse":"06b86e1a-668d-4d65-a5f0-7ba8a61fa57d","default_lakehouse_name":"ParkingDataLakehouse","default_lakehouse_workspace_id":"d3afc09a-dc29-418e-be57-836e9d2cc5f1"}}},"nbformat":4,"nbformat_minor":5}
{"cells":[{"cell_type":"code","source":["# =============================================================\n","# üîÅ OPEN MIRRORING CONFIGURATION (Auto-Healing Simulation Mode)\n","# =============================================================\n","\n","from pyspark.sql import SparkSession\n","from pyspark.sql.types import StructType, StructField, StringType\n","from pyspark.sql import functions as F\n","\n","class OpenMirroringManager:\n","    \"\"\"\n","    Handles configuration of Open Mirroring in Microsoft Fabric Lakehouse.\n","    Falls back to simulation mode outside Fabric, creating demo data if needed.\n","    \"\"\"\n","\n","    def __init__(self, spark: SparkSession, database_name=\"ParkingDataLakehouse\"):\n","        self.spark = spark\n","        self.database_name = database_name\n","\n","    # ---------------------------------------------------------\n","    # Step 1 ‚Äì Enable Fabric Mirroring (if supported)\n","    # ---------------------------------------------------------\n","    def configure_open_mirroring(self):\n","        print(\"üöÄ STARTING OPEN MIRRORING SETUP\")\n","        print(\"üîÑ CONFIGURING OPEN MIRRORING FOR DELTA REPLICATION...\")\n","\n","        try:\n","            cluster_info = self.spark.conf.get(\n","                \"spark.databricks.clusterUsageTags.clusterType\", \"\"\n","            ).lower()\n","\n","            if \"fabric\" in cluster_info or \"synapse\" in cluster_info:\n","                print(\"üß† Detected Microsoft Fabric runtime.\")\n","                self.spark.sql(f\"\"\"\n","                    ALTER DATABASE {self.database_name}\n","                    SET DBPROPERTIES ('enable_mirroring'='true')\n","                \"\"\")\n","                print(f\"‚úÖ Mirroring enabled for {self.database_name}\")\n","            else:\n","                print(\"üß© Non-Fabric runtime detected ‚Äî switching to simulation mode.\")\n","                print(\"‚ÑπÔ∏è Skipping ALTER DATABASE (Fabric-only feature).\")\n","        except Exception as e:\n","            print(f\"‚ö†Ô∏è Mirroring note: {e}\")\n","            print(\"‚öôÔ∏è Continuing in simulation mode...\")\n","\n","    # ---------------------------------------------------------\n","    # Step 2 ‚Äì Ensure mock tables exist (create if missing)\n","    # ---------------------------------------------------------\n","    def _ensure_table_exists(self, table_name: str):\n","        full_name = f\"{self.database_name}.{table_name}\"\n","        try:\n","            self.spark.table(full_name)\n","            print(f\"‚úÖ Found source table: {full_name}\")\n","            return True\n","        except Exception:\n","            print(f\"‚ÑπÔ∏è Table not found: {full_name} ‚Äî creating mock data...\")\n","\n","            # Create mock DataFrame per table\n","            if table_name == \"ParkingSensorData\":\n","                df = self.spark.createDataFrame([\n","                    (\"Zone A\", True, \"2025-10-11 08:00\", True, \"tx001\"),\n","                    (\"Zone B\", False, \"2025-10-11 08:05\", True, \"tx002\"),\n","                ], [\"parking_zone\", \"occupancy_status\", \"timestamp\",\n","                    \"blockchain_verified\", \"blockchain_tx_id\"])\n","\n","            elif table_name == \"TrafficCameraData\":\n","                df = self.spark.createDataFrame([\n","                    (\"Cam-1\", \"HIGH\", 0.85, 34, \"2025-10-11 08:00\"),\n","                    (\"Cam-2\", \"MEDIUM\", 0.50, 20, \"2025-10-11 08:05\"),\n","                ], [\"camera_id\", \"congestion_level\", \"traffic_density\",\n","                    \"vehicle_count\", \"timestamp\"])\n","\n","            elif table_name == \"YOLOProcessedData\":\n","                df = self.spark.createDataFrame([\n","                    (\"Cam-1\", 0.92, \"SUCCESS\", \"2025-10-11 08:00\"),\n","                    (\"Cam-2\", 0.78, \"SUCCESS\", \"2025-10-11 08:05\"),\n","                ], [\"camera_id\", \"processing_confidence\",\n","                    \"processing_status\", \"processed_at\"])\n","            else:\n","                schema = StructType([StructField(\"id\", StringType())])\n","                df = self.spark.createDataFrame([], schema)\n","\n","            # Ensure database exists\n","            self.spark.sql(f\"CREATE DATABASE IF NOT EXISTS {self.database_name}\")\n","            df.write.mode(\"overwrite\").format(\"delta\").saveAsTable(full_name)\n","            print(f\"‚úÖ Mock table created: {full_name}\")\n","            return True\n","\n","    # ---------------------------------------------------------\n","    # Step 3 ‚Äì Simulate Mirroring by copying to local schema\n","    # ---------------------------------------------------------\n","    def simulate_replication(self, table_names=None):\n","        if table_names is None:\n","            table_names = [\"ParkingSensorData\",\n","                           \"TrafficCameraData\",\n","                           \"YOLOProcessedData\"]\n","\n","        print(\"\\nüß± SIMULATING OPEN MIRRORING (Local Copy Mode)...\")\n","        self.spark.sql(\"CREATE DATABASE IF NOT EXISTS MirroredData\")\n","\n","        for table in table_names:\n","            src_table = f\"{self.database_name}.{table}\"\n","            dst_table = f\"MirroredData.{table}\"\n","\n","            self._ensure_table_exists(table)\n","\n","            try:\n","                df = self.spark.table(src_table)\n","                df.write.mode(\"overwrite\").format(\"delta\").saveAsTable(dst_table)\n","                print(f\"‚úÖ Mirrored table created: {dst_table} ({df.count()} rows)\")\n","            except Exception as e:\n","                print(f\"‚ö†Ô∏è Skipping {table}: {e}\")\n","\n","        print(\"üèÅ Mirroring simulation completed successfully.\\n\")\n","\n","# ---------------------------------------------------------\n","# ‚úÖ Optional standalone execution\n","# ---------------------------------------------------------\n","if __name__ == \"__main__\":\n","    spark = SparkSession.builder.appName(\"OpenMirroringSetup\").getOrCreate()\n","    mgr = OpenMirroringManager(spark)\n","    mgr.configure_open_mirroring()\n","    mgr.simulate_replication()\n","    print(\"‚úÖ Open Mirroring setup completed successfully.\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":3,"statement_ids":[3],"state":"finished","livy_statement_state":"available","session_id":"36585711-9b79-4c83-8c72-643e2aa1302f","normalized_state":"finished","queued_time":"2025-10-17T16:24:51.6021152Z","session_start_time":"2025-10-17T16:24:51.6033984Z","execution_start_time":"2025-10-17T16:25:05.2394374Z","execution_finish_time":"2025-10-17T16:25:57.364791Z","parent_msg_id":"fd2bef98-b157-4e44-8e89-3b414b6683a8"},"text/plain":"StatementMeta(, 36585711-9b79-4c83-8c72-643e2aa1302f, 3, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["üöÄ STARTING OPEN MIRRORING SETUP\nüîÑ CONFIGURING OPEN MIRRORING FOR DELTA REPLICATION...\nüß© Non-Fabric runtime detected ‚Äî switching to simulation mode.\n‚ÑπÔ∏è Skipping ALTER DATABASE (Fabric-only feature).\n\nüß± SIMULATING OPEN MIRRORING (Local Copy Mode)...\n‚úÖ Found source table: ParkingDataLakehouse.ParkingSensorData\n‚úÖ Mirrored table created: MirroredData.ParkingSensorData (2 rows)\n‚úÖ Found source table: ParkingDataLakehouse.TrafficCameraData\n‚úÖ Mirrored table created: MirroredData.TrafficCameraData (2 rows)\n‚úÖ Found source table: ParkingDataLakehouse.YOLOProcessedData\n‚úÖ Mirrored table created: MirroredData.YOLOProcessedData (2 rows)\nüèÅ Mirroring simulation completed successfully.\n\n‚úÖ Open Mirroring setup completed successfully.\n"]}],"execution_count":1,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"47c76208-7d6e-44e9-a7c9-c72116612aa6"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"known_lakehouses":[{"id":"06b86e1a-668d-4d65-a5f0-7ba8a61fa57d"}],"default_lakehouse":"06b86e1a-668d-4d65-a5f0-7ba8a61fa57d","default_lakehouse_name":"ParkingDataLakehouse","default_lakehouse_workspace_id":"d3afc09a-dc29-418e-be57-836e9d2cc5f1"}}},"nbformat":4,"nbformat_minor":5}
{"cells":[{"cell_type":"code","source":["!pip install sentence-transformers faiss-cpu openai tiktoken pandas langchain\n","# if on GPU environment, install faiss-gpu instead of faiss-cpu"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":5,"statement_ids":[5],"state":"finished","livy_statement_state":"available","session_id":"51092528-9a67-4cd9-8ddb-e4d226a73748","normalized_state":"finished","queued_time":"2025-10-11T02:36:44.6885155Z","session_start_time":null,"execution_start_time":"2025-10-11T02:36:44.6897085Z","execution_finish_time":"2025-10-11T02:39:42.7291923Z","parent_msg_id":"23a00c78-274f-472f-8f73-ffdadae9ac2a"},"text/plain":"StatementMeta(, 51092528-9a67-4cd9-8ddb-e4d226a73748, 5, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Collecting sentence-transformers\n  Using cached sentence_transformers-5.1.1-py3-none-any.whl.metadata (16 kB)\nCollecting faiss-cpu\n  Using cached faiss_cpu-1.12.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\nCollecting openai\n  Using cached openai-2.3.0-py3-none-any.whl.metadata (29 kB)\nCollecting tiktoken\n  Using cached tiktoken-0.12.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.7 kB)\nRequirement already satisfied: pandas in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (2.1.4)\nCollecting langchain\n  Downloading langchain-0.3.27-py3-none-any.whl.metadata (7.8 kB)\nCollecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)\n  Downloading transformers-4.57.0-py3-none-any.whl.metadata (41 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.4/41.4 kB\u001b[0m \u001b[31m221.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: tqdm in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from sentence-transformers) (4.65.0)\nRequirement already satisfied: torch>=1.11.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from sentence-transformers) (2.2.1)\nRequirement already satisfied: scikit-learn in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from sentence-transformers) (1.11.4)\nRequirement already satisfied: huggingface-hub>=0.20.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from sentence-transformers) (0.23.1)\nRequirement already satisfied: Pillow in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from sentence-transformers) (10.2.0)\nRequirement already satisfied: typing_extensions>=4.5.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from sentence-transformers) (4.9.0)\nRequirement already satisfied: numpy<3.0,>=1.25.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from faiss-cpu) (1.26.4)\nRequirement already satisfied: packaging in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from faiss-cpu) (23.1)\nRequirement already satisfied: anyio<5,>=3.5.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from openai) (4.2.0)\nRequirement already satisfied: distro<2,>=1.7.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from openai) (1.8.0)\nCollecting httpx<1,>=0.23.0 (from openai)\n  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\nCollecting jiter<1,>=0.10.0 (from openai)\n  Downloading jiter-0.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\nCollecting pydantic<3,>=1.9.0 (from openai)\n  Downloading pydantic-2.12.0-py3-none-any.whl.metadata (83 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.4/83.4 kB\u001b[0m \u001b[31m447.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: sniffio in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from openai) (1.3.0)\nCollecting typing_extensions>=4.5.0 (from sentence-transformers)\n  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\nRequirement already satisfied: regex>=2022.1.18 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from tiktoken) (2023.10.3)\nRequirement already satisfied: requests>=2.26.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from tiktoken) (2.31.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from pandas) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from pandas) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from pandas) (2023.3)\nCollecting langchain-core<1.0.0,>=0.3.72 (from langchain)\n  Downloading langchain_core-0.3.79-py3-none-any.whl.metadata (3.2 kB)\nCollecting langchain-text-splitters<1.0.0,>=0.3.9 (from langchain)\n  Downloading langchain_text_splitters-0.3.11-py3-none-any.whl.metadata (1.8 kB)\nCollecting langsmith>=0.1.17 (from langchain)\n  Downloading langsmith-0.4.34-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from langchain) (2.0.25)\nRequirement already satisfied: PyYAML>=5.3 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from langchain) (6.0.1)\nRequirement already satisfied: idna>=2.8 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.4)\nRequirement already satisfied: certifi in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\nCollecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\nCollecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\nRequirement already satisfied: filelock in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.1)\nRequirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (8.2.3)\nCollecting jsonpatch<2.0.0,>=1.33.0 (from langchain-core<1.0.0,>=0.3.72->langchain)\n  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\nCollecting packaging (from faiss-cpu)\n  Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\nCollecting orjson>=3.9.14 (from langsmith>=0.1.17->langchain)\n  Downloading orjson-3.11.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting requests-toolbelt>=1.0.0 (from langsmith>=0.1.17->langchain)\n  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\nCollecting zstandard>=0.23.0 (from langsmith>=0.1.17->langchain)\n  Downloading zstandard-0.25.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.3 kB)\nCollecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->openai)\n  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\nCollecting pydantic-core==2.41.1 (from pydantic<3,>=1.9.0->openai)\n  Downloading pydantic_core-2.41.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\nCollecting typing-inspection>=0.4.2 (from pydantic<3,>=1.9.0->openai)\n  Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\nRequirement already satisfied: six>=1.5 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken) (2.0.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken) (2.1.0)\nRequirement already satisfied: greenlet!=0.4.17 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\nRequirement already satisfied: sympy in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\nRequirement already satisfied: networkx in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.1)\nRequirement already satisfied: jinja2 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\nCollecting huggingface-hub>=0.20.0 (from sentence-transformers)\n  Downloading huggingface_hub-0.35.3-py3-none-any.whl.metadata (14 kB)\nCollecting tokenizers<=0.23.0,>=0.22.0 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n  Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\nCollecting safetensors>=0.4.3 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n  Downloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\nCollecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub>=0.20.0->sentence-transformers)\n  Downloading hf_xet-1.1.10-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.7 kB)\nRequirement already satisfied: joblib>=1.1.1 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (1.2.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (2.2.0)\nRequirement already satisfied: jsonpointer>=1.9 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.72->langchain) (2.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\nDownloading sentence_transformers-5.1.1-py3-none-any.whl (486 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m486.6/486.6 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n\u001b[?25hDownloading faiss_cpu-1.12.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (31.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading openai-2.3.0-py3-none-any.whl (999 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m999.8/999.8 kB\u001b[0m \u001b[31m65.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tiktoken-0.12.0-cp311-cp311-manylinux_2_28_x86_64.whl (1.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m70.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain-0.3.27-py3-none-any.whl (1.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading httpx-0.28.1-py3-none-any.whl (73 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading jiter-0.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (348 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m349.0/349.0 kB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_core-0.3.79-py3-none-any.whl (449 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m449.8/449.8 kB\u001b[0m \u001b[31m66.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_text_splitters-0.3.11-py3-none-any.whl (33 kB)\nDownloading langsmith-0.4.34-py3-none-any.whl (386 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m387.0/387.0 kB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading packaging-25.0-py3-none-any.whl (66 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pydantic-2.12.0-py3-none-any.whl (459 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.7/459.7 kB\u001b[0m \u001b[31m65.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pydantic_core-2.41.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading transformers-4.57.0-py3-none-any.whl (12.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading huggingface_hub-0.35.3-py3-none-any.whl (564 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m564.3/564.3 kB\u001b[0m \u001b[31m62.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\nDownloading hf_xet-1.1.10-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\nDownloading orjson-3.11.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (132 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.7/132.7 kB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (485 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.8/485.8 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\nDownloading zstandard-0.25.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (5.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading h11-0.16.0-py3-none-any.whl (37 kB)\nInstalling collected packages: zstandard, typing_extensions, safetensors, packaging, orjson, jsonpatch, jiter, hf-xet, h11, annotated-types, typing-inspection, tiktoken, requests-toolbelt, pydantic-core, huggingface-hub, httpcore, faiss-cpu, tokenizers, pydantic, httpx, transformers, openai, langsmith, sentence-transformers, langchain-core, langchain-text-splitters, langchain\n  Attempting uninstall: zstandard\n    Found existing installation: zstandard 0.19.0\n    Uninstalling zstandard-0.19.0:\n      Successfully uninstalled zstandard-0.19.0\n  Attempting uninstall: typing_extensions\n    Found existing installation: typing_extensions 4.9.0\n    Uninstalling typing_extensions-4.9.0:\n      Successfully uninstalled typing_extensions-4.9.0\n  Attempting uninstall: safetensors\n    Found existing installation: safetensors 0.4.2\n    Uninstalling safetensors-0.4.2:\n      Successfully uninstalled safetensors-0.4.2\n  Attempting uninstall: packaging\n    Found existing installation: packaging 23.1\n    Uninstalling packaging-23.1:\n      Successfully uninstalled packaging-23.1\n  Attempting uninstall: jsonpatch\n    Found existing installation: jsonpatch 1.32\n    Uninstalling jsonpatch-1.32:\n      Successfully uninstalled jsonpatch-1.32\n  Attempting uninstall: huggingface-hub\n    Found existing installation: huggingface_hub 0.23.1\n    Uninstalling huggingface_hub-0.23.1:\n      Successfully uninstalled huggingface_hub-0.23.1\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.15.1\n    Uninstalling tokenizers-0.15.1:\n      Successfully uninstalled tokenizers-0.15.1\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.37.2\n    Uninstalling transformers-4.37.2:\n      Successfully uninstalled transformers-4.37.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nnni 3.0 requires filelock<3.12, but you have filelock 3.13.1 which is incompatible.\nmlflow-skinny 2.12.2 requires packaging<25, but you have packaging 25.0 which is incompatible.\nfsspec-wrapper 0.1.15 requires PyJWT>=2.6.0, but you have pyjwt 2.4.0 which is incompatible.\ndatasets 2.19.1 requires fsspec[http]<=2024.3.1,>=2023.1.0, but you have fsspec 2024.6.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed annotated-types-0.7.0 faiss-cpu-1.12.0 h11-0.16.0 hf-xet-1.1.10 httpcore-1.0.9 httpx-0.28.1 huggingface-hub-0.35.3 jiter-0.11.0 jsonpatch-1.33 langchain-0.3.27 langchain-core-0.3.79 langchain-text-splitters-0.3.11 langsmith-0.4.34 openai-2.3.0 orjson-3.11.3 packaging-25.0 pydantic-2.12.0 pydantic-core-2.41.1 requests-toolbelt-1.0.0 safetensors-0.6.2 sentence-transformers-5.1.1 tiktoken-0.12.0 tokenizers-0.22.1 transformers-4.57.0 typing-inspection-0.4.2 typing_extensions-4.15.0 zstandard-0.25.0\n"]}],"execution_count":3,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"5109ba79-e85e-43f4-b05b-6cee351c13be"},{"cell_type":"code","source":["# Upgrade typing_extensions to a compatible version\n","%pip install --upgrade typing_extensions pydantic openai --quiet"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":12,"statement_ids":[7,8,9,10,11,12],"state":"finished","livy_statement_state":"available","session_id":"51092528-9a67-4cd9-8ddb-e4d226a73748","normalized_state":"finished","queued_time":"2025-10-11T02:42:57.3669891Z","session_start_time":null,"execution_start_time":"2025-10-11T02:42:57.3688768Z","execution_finish_time":"2025-10-11T02:43:19.5168177Z","parent_msg_id":"4e08976a-6aa9-4daf-8898-bff66d1d1ebe"},"text/plain":"StatementMeta(, 51092528-9a67-4cd9-8ddb-e4d226a73748, 12, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\nNote: you may need to restart the kernel to use updated packages.\nWarning: PySpark kernel has been restarted to use updated packages.\n\n"]}],"execution_count":5,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"21620927-d8c0-43a9-806c-847d9d8cb548"},{"cell_type":"code","source":["import openai\n","print(\"✅ OpenAI library imported successfully.\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":14,"statement_ids":[14],"state":"finished","livy_statement_state":"available","session_id":"51092528-9a67-4cd9-8ddb-e4d226a73748","normalized_state":"finished","queued_time":"2025-10-11T02:43:39.6713074Z","session_start_time":null,"execution_start_time":"2025-10-11T02:43:44.233976Z","execution_finish_time":"2025-10-11T02:43:45.7861998Z","parent_msg_id":"b74864c8-b4fc-4445-9b84-073c694ff21d"},"text/plain":"StatementMeta(, 51092528-9a67-4cd9-8ddb-e4d226a73748, 14, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ OpenAI library imported successfully.\n"]}],"execution_count":6,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"d7e09383-9de1-40c4-93e3-419d7eefa812"},{"cell_type":"code","source":["\"\"\"\n","RAG Assistant for Reimage-AI Smart Parking\n","- Builds embeddings from HistoricalTraffic (and optionally other) Fabric tables\n","- Stores vector index using FAISS\n","- Answers queries by retrieving top-k contexts and (optionally) calling OpenAI for generation\n","- Logs queries/answers to MCP (ModelContextProtocol) and Hedera simulation via mcp.log_inference()\n","\"\"\"\n","\n","import os\n","import json\n","import faiss\n","import numpy as np\n","import pandas as pd\n","from datetime import datetime\n","from sentence_transformers import SentenceTransformer\n","from typing import List, Dict, Optional\n","\n","# Optional OpenAI usage for generation; if not set, assistant falls back to extractive answers\n","import openai\n","\n","# ---- Config ----\n","EMBEDDING_MODEL_NAME = \"all-MiniLM-L6-v2\"   # small & fast embedding model from sentence-transformers\n","FAISS_INDEX_PATH = \"data/faiss_index.index\"\n","DOCS_META_PATH = \"data/faiss_docs_meta.json\"\n","TOP_K = 5\n","USE_OPENAI = bool(os.getenv(\"OPENAI_API_KEY\", \"\"))\n","\n","if USE_OPENAI:\n","    openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n","\n","# ---- Helper classes ----\n","class RAGAssistant:\n","    def __init__(self,\n","                 spark,\n","                 embedding_model_name: str = EMBEDDING_MODEL_NAME,\n","                 index_path: str = FAISS_INDEX_PATH,\n","                 docs_meta_path: str = DOCS_META_PATH):\n","        \"\"\"\n","        spark: active SparkSession (so we can read tables from Fabric Lakehouse)\n","        \"\"\"\n","        self.spark = spark\n","        self.embedding_model_name = embedding_model_name\n","        self.index_path = index_path\n","        self.docs_meta_path = docs_meta_path\n","\n","        # Load embedding model\n","        print(f\"[RAG] Loading embedding model: {self.embedding_model_name}\")\n","        self.embedder = SentenceTransformer(self.embedding_model_name)\n","\n","        # placeholders\n","        self.index = None\n","        self.doc_metas = []   # list of dicts {id, text, source, metadata...}\n","        if os.path.exists(self.index_path) and os.path.exists(self.docs_meta_path):\n","            try:\n","                print(\"[RAG] Loading existing FAISS index and metadata...\")\n","                self._load_index()\n","                print(\"[RAG] Index loaded.\")\n","            except Exception as e:\n","                print(\"[RAG] Warning: failed to load existing index:\", e)\n","                self.index = None\n","                self.doc_metas = []\n","\n","    # ------------------------------\n","    # Build vector store from HistoricalTraffic (and optionally other tables)\n","    # ------------------------------\n","    def build_vector_store(self, tables: List[str] = [\"HistoricalTraffic\"], text_columns: List[str] = None, force_rebuild: bool = False):\n","        \"\"\"\n","        Build or rebuild the FAISS vector index from specified Spark table(s).\n","\n","        - tables: list of table names to pull rows from (Spark SQL). Default: HistoricalTraffic.\n","        - text_columns: if provided, list of columns to concatenate per document (e.g., ['zone_id','date','hour','average_occupancy'])\n","        - force_rebuild: if True, rebuild even if an index already exists\n","        \"\"\"\n","        if not force_rebuild and self.index is not None:\n","            print(\"[RAG] Index already present. Use force_rebuild=True to rebuild.\")\n","            return\n","\n","        print(f\"[RAG] Reading data from tables: {tables}\")\n","        docs = []\n","        for table in tables:\n","            try:\n","                df = self.spark.sql(f\"SELECT * FROM {table}\")\n","                pdf = df.toPandas()\n","                print(f\"[RAG] Retrieved {len(pdf)} rows from {table}\")\n","            except Exception as e:\n","                print(f\"[RAG] Warning: failed to read table {table}: {e}\")\n","                continue\n","\n","            # Form documents\n","            for idx, row in pdf.iterrows():\n","                # Compose a human-readable text from chosen columns\n","                if text_columns:\n","                    parts = []\n","                    for c in text_columns:\n","                        parts.append(f\"{c}: {row.get(c, '')}\")\n","                    text = \" | \".join(parts)\n","                else:\n","                    # Default textualization: join important fields\n","                    # Protect against NaNs by converting to str\n","                    text = f\"zone_id: {row.get('zone_id','')}, date: {row.get('date','')}, hour: {row.get('hour','')}, occupancy: {row.get('average_occupancy','')}, volume: {row.get('traffic_volume','')}, weather: {row.get('weather_condition','')}\"\n","                meta = {\n","                    \"source_table\": table,\n","                    \"source_row_index\": int(idx),\n","                    \"zone_id\": str(row.get(\"zone_id\", \"\")),\n","                    \"date\": str(row.get(\"date\", \"\")),\n","                    \"hour\": int(row.get(\"hour\")) if not pd.isna(row.get(\"hour\")) else None,\n","                    \"data_hash\": row.get(\"data_hash\", None)\n","                }\n","                docs.append({\"id\": f\"{table}__{idx}\", \"text\": text, \"meta\": meta})\n","\n","        if not docs:\n","            print(\"[RAG] No documents to index.\")\n","            return\n","\n","        # Create embeddings in batches\n","        texts = [d[\"text\"] for d in docs]\n","        print(\"[RAG] Computing embeddings for documents...\")\n","        embeddings = self.embedder.encode(texts, show_progress_bar=True, convert_to_numpy=True)\n","        dim = embeddings.shape[1]\n","        print(f\"[RAG] Embeddings shape: {embeddings.shape}  dim={dim}\")\n","\n","        # Build FAISS index (IndexFlatIP with normalization -> cosine similarity by inner product after normalization)\n","        print(\"[RAG] Building FAISS index (normalized vectors)...\")\n","        faiss.normalize_L2(embeddings)\n","        index = faiss.IndexFlatIP(dim)\n","        index.add(embeddings)\n","\n","        # Save index and metadata\n","        faiss.write_index(index, self.index_path)\n","        with open(self.docs_meta_path, \"w\", encoding=\"utf-8\") as fh:\n","            json.dump(docs, fh, ensure_ascii=False, indent=2)\n","\n","        # assign to object\n","        self.index = index\n","        self.doc_metas = docs\n","        print(f\"[RAG] FAISS index built and saved to {self.index_path}. Documents saved to {self.docs_meta_path}.\")\n","\n","    # ------------------------------\n","    # Internal load index\n","    # ------------------------------\n","    def _load_index(self):\n","        self.index = faiss.read_index(self.index_path)\n","        with open(self.docs_meta_path, \"r\", encoding=\"utf-8\") as fh:\n","            self.doc_metas = json.load(fh)\n","\n","    # ------------------------------\n","    # Query / Retrieve\n","    # ------------------------------\n","    def retrieve(self, query: str, top_k: int = TOP_K) -> List[Dict]:\n","        \"\"\"\n","        Return top_k retrieved documents with scores.\n","        \"\"\"\n","        if self.index is None:\n","            raise RuntimeError(\"FAISS index not built. Call build_vector_store() first.\")\n","\n","        q_emb = self.embedder.encode([query], convert_to_numpy=True)\n","        faiss.normalize_L2(q_emb)\n","        D, I = self.index.search(q_emb, top_k)  # D: similarity scores; I: indices\n","        results = []\n","        for score, idx in zip(D[0], I[0]):\n","            if idx < 0 or idx >= len(self.doc_metas):\n","                continue\n","            doc = self.doc_metas[idx]\n","            results.append({\n","                \"id\": doc[\"id\"],\n","                \"text\": doc[\"text\"],\n","                \"meta\": doc[\"meta\"],\n","                \"score\": float(score)\n","            })\n","        return results\n","\n","    # ------------------------------\n","    # Answer generation (RAG)\n","    # ------------------------------\n","    def answer(self,\n","               query: str,\n","               top_k: int = TOP_K,\n","               use_openai: bool = USE_OPENAI,\n","               openai_model: str = \"gpt-3.5-turbo\",\n","               llm_temperature: float = 0.0,\n","               mcp_system = None):\n","        \"\"\"\n","        Full RAG answer flow:\n","        - retrieve top_k documents\n","        - craft a prompt combining query + retrieved contexts\n","        - optionally call OpenAI to generate final answer\n","        - log query & answer to MCP (if provided)\n","        \"\"\"\n","        retrieved = self.retrieve(query, top_k=top_k)\n","        # Simple extractive fallback if no LLM\n","        context_texts = [f\"[{r['meta']['zone_id']}|{r['meta']['date']}|h{r['meta']['hour']}] {r['text']}\" for r in retrieved]\n","\n","        # Compose system prompt\n","        prompt_header = (\n","            \"You are a traffic & parking assistant. Use the contextual historical traffic data below \"\n","            \"to answer the user's query. Cite relevant zone and hour where appropriate.\\n\\n\"\n","        )\n","        context_block = \"\\n\\n\".join([f\"Context {i+1} (score={r['score']:.3f}):\\n{r['text']}\" for i, r in enumerate(retrieved)])\n","        final_prompt = prompt_header + context_block + f\"\\n\\nUser Query: {query}\\n\\nAnswer concisely with supporting context.\"\n","\n","        if use_openai:\n","            try:\n","                print(\"[RAG] Calling OpenAI to generate answer...\")\n","                response = openai.ChatCompletion.create(\n","                    model=openai_model,\n","                    messages=[\n","                        {\"role\": \"system\", \"content\": \"You are a helpful assistant specialized in traffic and parking analytics.\"},\n","                        {\"role\": \"user\", \"content\": final_prompt}\n","                    ],\n","                    temperature=llm_temperature,\n","                    max_tokens=512\n","                )\n","                answer_text = response[\"choices\"][0][\"message\"][\"content\"].strip()\n","            except Exception as e:\n","                print(\"[RAG] OpenAI call failed:\", e)\n","                # fallback to return retrieved context\n","                answer_text = \" \".join(context_texts) if context_texts else \"No context available to answer the query.\"\n","        else:\n","            # Fallback behaviour: return retrieved contexts concatenated (extractive RAG)\n","            print(\"[RAG] OPENAI key not provided — returning retrieved contexts as answer.\")\n","            if context_texts:\n","                answer_text = \"Retrieved context (top results):\\n\\n\" + \"\\n\\n\".join(context_texts)\n","            else:\n","                answer_text = \"No relevant historical traffic context found.\"\n","\n","        # Log query+answer to MCP if available (so it becomes an audited inference)\n","        if mcp_system is not None:\n","            try:\n","                inference_meta = {\n","                    \"query\": query,\n","                    \"retrieved_ids\": [r[\"id\"] for r in retrieved],\n","                    \"retrieved_scores\": [r[\"score\"] for r in retrieved],\n","                    \"answer_summary\": answer_text[:800]  # truncated summary for ledger entry\n","                }\n","                # Use mcp.log_inference to log; this returns receipt (with transaction_id)\n","                receipt = mcp_system.log_inference(\"RAG_Traffic_Assistant_v1\", {\"query\": query}, {\"answer\": answer_text}, confidence=0.9)\n","                # attach receipt info if present\n","                if receipt:\n","                    inference_tx_id = receipt.get(\"transaction_id\") if isinstance(receipt, dict) else receipt\n","                else:\n","                    inference_tx_id = None\n","            except Exception as e:\n","                print(\"[RAG] Error logging to MCP:\", e)\n","                inference_tx_id = None\n","        else:\n","            inference_tx_id = None\n","\n","        return {\n","            \"query\": query,\n","            \"answer\": answer_text,\n","            \"retrieved\": retrieved,\n","            \"mcp_inference_tx\": inference_tx_id,\n","            \"timestamp\": datetime.utcnow().isoformat()\n","        }\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":16,"statement_ids":[16],"state":"finished","livy_statement_state":"available","session_id":"51092528-9a67-4cd9-8ddb-e4d226a73748","normalized_state":"finished","queued_time":"2025-10-11T02:44:18.182822Z","session_start_time":null,"execution_start_time":"2025-10-11T02:44:18.1844594Z","execution_finish_time":"2025-10-11T02:44:19.3953402Z","parent_msg_id":"74a01966-dfa7-462b-a4a6-6030f2213bf3"},"text/plain":"StatementMeta(, 51092528-9a67-4cd9-8ddb-e4d226a73748, 16, Finished, Available, Finished)"},"metadata":{}}],"execution_count":8,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"a4e9f9f9-793f-4484-9c14-1bd66c11bf69"},{"cell_type":"code","source":["# from rag_assistant import RAGAssistant\n","\n","# assume spark is the active SparkSession in your Fabric notebook\n","rag = RAGAssistant(spark)\n","\n","import os\n","os.makedirs(\"data\", exist_ok=True)\n","\n","# build embeddings/index from HistoricalTraffic\n","rag.build_vector_store(tables=[\"HistoricalTraffic\"], force_rebuild=True)\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":20,"statement_ids":[20],"state":"finished","livy_statement_state":"available","session_id":"51092528-9a67-4cd9-8ddb-e4d226a73748","normalized_state":"finished","queued_time":"2025-10-11T02:49:25.0866472Z","session_start_time":null,"execution_start_time":"2025-10-11T02:49:25.087908Z","execution_finish_time":"2025-10-11T02:49:35.2736508Z","parent_msg_id":"7d80b244-3896-433d-aaca-c7fdd4723c2f"},"text/plain":"StatementMeta(, 51092528-9a67-4cd9-8ddb-e4d226a73748, 20, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["[RAG] Loading embedding model: all-MiniLM-L6-v2\n[RAG] Reading data from tables: ['HistoricalTraffic']\n[RAG] Retrieved 672 rows from HistoricalTraffic\n[RAG] Computing embeddings for documents...\n"]},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/21 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c000951a67a0442ea80cd6e23bb3ecd1"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["[RAG] Embeddings shape: (672, 384)  dim=384\n[RAG] Building FAISS index (normalized vectors)...\n[RAG] FAISS index built and saved to data/faiss_index.index. Documents saved to data/faiss_docs_meta.json.\n"]},{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":21,"statement_ids":[21],"state":"finished","livy_statement_state":"available","session_id":"51092528-9a67-4cd9-8ddb-e4d226a73748","normalized_state":"finished","queued_time":"2025-10-11T02:49:39.5639658Z","session_start_time":null,"execution_start_time":"2025-10-11T02:49:39.566177Z","execution_finish_time":"2025-10-11T02:49:40.5033954Z","parent_msg_id":"b19ad10b-1d9f-4f98-9b19-00d5fc85daab"},"text/plain":"StatementMeta(, 51092528-9a67-4cd9-8ddb-e4d226a73748, 21, Finished, Available, Finished)"},"metadata":{}}],"execution_count":12,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"ae891424-da83-4216-a6ae-337b4ce6be60"},{"cell_type":"code","source":["result = rag.answer(\n","    \"Which zones have the highest average occupancy during weekday mornings (8-10am)?\",\n","    top_k=6)\n","\n","print(\"ANSWER:\\n\", result[\"answer\"])\n","print(\"\\nRetrieved docs:\")\n","for r in result[\"retrieved\"]:\n","    print(\"-\", r[\"meta\"].get(\"zone_id\"), r[\"meta\"].get(\"date\"), \"score:\", r[\"score\"])"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":26,"statement_ids":[26],"state":"finished","livy_statement_state":"available","session_id":"51092528-9a67-4cd9-8ddb-e4d226a73748","normalized_state":"finished","queued_time":"2025-10-11T02:58:54.9060194Z","session_start_time":null,"execution_start_time":"2025-10-11T02:58:54.9070946Z","execution_finish_time":"2025-10-11T02:58:55.2043221Z","parent_msg_id":"7374cf91-4e4d-41ab-839b-2702d9ab464a"},"text/plain":"StatementMeta(, 51092528-9a67-4cd9-8ddb-e4d226a73748, 26, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["[RAG] Calling OpenAI to generate answer...\n[RAG] OpenAI call failed: \n\nYou tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n\nANSWER:\n [ZONE_B|2025-10-03|h20] zone_id: ZONE_B, date: 2025-10-03, hour: 20, occupancy: 0.147, volume: 279, weather: Sunny [ZONE_B|2025-10-09|h3] zone_id: ZONE_B, date: 2025-10-09, hour: 3, occupancy: 0.148, volume: 279, weather: Rainy [ZONE_A|2025-10-03|h7] zone_id: ZONE_A, date: 2025-10-03, hour: 7, occupancy: 0.139, volume: 253, weather: Sunny [ZONE_B|2025-10-08|h7] zone_id: ZONE_B, date: 2025-10-08, hour: 7, occupancy: 0.267, volume: 171, weather: Sunny [ZONE_A|2025-10-09|h6] zone_id: ZONE_A, date: 2025-10-09, hour: 6, occupancy: 0.341, volume: 266, weather: Sunny [ZONE_D|2025-10-06|h6] zone_id: ZONE_D, date: 2025-10-06, hour: 6, occupancy: 0.309, volume: 336, weather: Cloudy\n\nRetrieved docs:\n- ZONE_B 2025-10-03 score: 0.5703167915344238\n- ZONE_B 2025-10-09 score: 0.5594474077224731\n- ZONE_A 2025-10-03 score: 0.5566945672035217\n- ZONE_B 2025-10-08 score: 0.5556610822677612\n- ZONE_A 2025-10-09 score: 0.5546510815620422\n- ZONE_D 2025-10-06 score: 0.553027331829071\n"]}],"execution_count":17,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"20192b2a-1ed3-40de-bb07-af36f2a756ba"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"widgets":{"application/vnd.jupyter.widget-state+json":{"version_major":2,"version_minor":0,"state":{"53b918c377ad477b8ba77d97170fbafc":{"model_name":"LayoutModel","model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","state":{}},"527b65423cc84e28b338c47fe0a1be7b":{"model_name":"LayoutModel","model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","state":{}},"136f71dd14044b76876975a96cf1d1ae":{"model_name":"LayoutModel","model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","state":{}},"f99d2065eb584cdda82b2e830d2bc16f":{"model_name":"ProgressStyleModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"description_width":""}},"17e9134bc8df466da55ea7be3a16d0e9":{"model_name":"ProgressStyleModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"description_width":""}},"fcb7b955bf46416cb979e3b3b4ab0b8c":{"model_name":"HTMLStyleModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"description_width":"","font_size":null,"text_color":null}},"5410e2503bc6435295d2738226c8d96e":{"model_name":"LayoutModel","model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","state":{}},"5d3f2897039844e295bbdbafe4163392":{"model_name":"HBoxModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"children":["IPY_MODEL_c828c8d58eb14ab8b5a76dd58edb5984","IPY_MODEL_7fdd28e4409b435ab5370e653b2200a7","IPY_MODEL_faf8753711074b4086941a68612bd1ff"],"layout":"IPY_MODEL_4631b3607cb3488fa4e4509fd9c3fce9"}},"f7c883301ef54f1ca2ded7a41145f83d":{"model_name":"FloatProgressModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"value":90868376,"max":90868376,"bar_style":"success","style":"IPY_MODEL_d306fd6e7a5d4fb3a46e7de053d30fe7","layout":"IPY_MODEL_0d14e1baaa3c4af2a79b88b4257ac5e5"}},"41cae6989bc8484e85504d90856c7c6d":{"model_name":"HTMLStyleModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"description_width":"","font_size":null,"text_color":null}},"ebbf1bc5804f4a4389945fdb75120195":{"model_name":"LayoutModel","model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","state":{}},"dba6161cbfd144d98033bc38bf2af5a2":{"model_name":"ProgressStyleModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"description_width":""}},"9206ad36106245bba4855e635d2f2134":{"model_name":"HTMLStyleModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"description_width":"","font_size":null,"text_color":null}},"6ce752d3cff74cca88a077c065f17baf":{"model_name":"HTMLStyleModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"description_width":"","font_size":null,"text_color":null}},"cf0180147f4749e1ac71fe57fba93e30":{"model_name":"HTMLStyleModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"description_width":"","font_size":null,"text_color":null}},"bb4c83a5c3ef4780a1554ef5656fe49c":{"model_name":"HTMLStyleModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"description_width":"","font_size":null,"text_color":null}},"d03576a2f3d548bebcd6167897eb0627":{"model_name":"LayoutModel","model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","state":{}},"e378e34bb7b2453da8fe1fd3b3408551":{"model_name":"LayoutModel","model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","state":{}},"faf8753711074b4086941a68612bd1ff":{"model_name":"HTMLModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"value":" 112/112 [00:00&lt;00:00, 14.3kB/s]","layout":"IPY_MODEL_185a4bc84fb6455ab4a43cc519c63847","style":"IPY_MODEL_6fddce0423bb4e339fb3fde5f1d0a1de"}},"12244a5eca40475785b8a4da4d68bff1":{"model_name":"LayoutModel","model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","state":{}},"11d7bca689184a8686161c3898a90c36":{"model_name":"ProgressStyleModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"description_width":""}},"c05d9f015813442980981b344b9a776d":{"model_name":"LayoutModel","model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","state":{}},"c399919ef6c14daa9a6e386bf2d69631":{"model_name":"HTMLModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"value":"sentence_bert_config.json: 100%","layout":"IPY_MODEL_72e6aca9b42f4517a03feb4f35dcf6dd","style":"IPY_MODEL_a0c4bf40a66d4debad69942dd7a5e91a"}},"1181017a5761408db9898ed0005461d3":{"model_name":"HTMLModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"value":" 349/349 [00:00&lt;00:00, 41.7kB/s]","layout":"IPY_MODEL_8f832dc8a3294c5e9c3a6a2565dbf93c","style":"IPY_MODEL_480ff79fe5f04b509da95896b7ea7644"}},"58d4fbff663b49fca7ec3e2e57c2e05c":{"model_name":"LayoutModel","model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","state":{}},"00592cd1444040b9b69cc77d889f0832":{"model_name":"ProgressStyleModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"description_width":""}},"6a406b85b381469ebeae5ba8b694d6c3":{"model_name":"LayoutModel","model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","state":{}},"ad0201490828499faa4b90015b9d6c7e":{"model_name":"LayoutModel","model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","state":{}},"c0a2034062324c55bcbac9320df43834":{"model_name":"LayoutModel","model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","state":{}},"7fdd28e4409b435ab5370e653b2200a7":{"model_name":"FloatProgressModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"value":112,"max":112,"bar_style":"success","style":"IPY_MODEL_4c2166c908de472a8bcee1852390074f","layout":"IPY_MODEL_f2aa5dd448b34024a05269724544bb89"}},"32dee6ce91314d05b3cccc3c3d05e5fe":{"model_name":"HBoxModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"children":["IPY_MODEL_8c56b51115224c2bbcda76d0e03554c7","IPY_MODEL_ea7de4ba61d64e1f8c750e23bff11ab8","IPY_MODEL_49efba11652647ab85d7bdab84984910"],"layout":"IPY_MODEL_12bf441026404434b7d4b084ed26c4b6"}},"13d00f1ca31a43b18a0081d3ecc39855":{"model_name":"LayoutModel","model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","state":{}},"3f608c39ca0d4d0e9f5f9906bc658d54":{"model_name":"HTMLModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"value":"modules.json: 100%","layout":"IPY_MODEL_c28ea8f2c4ee45fea157d6911c44bce4","style":"IPY_MODEL_364a504cb84043ea9e9c69ae90f2fd33"}},"364a504cb84043ea9e9c69ae90f2fd33":{"model_name":"HTMLStyleModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"description_width":"","font_size":null,"text_color":null}},"72c8f7c0274c45549f05223f6455dc23":{"model_name":"FloatProgressModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"value":350,"max":350,"bar_style":"success","style":"IPY_MODEL_00592cd1444040b9b69cc77d889f0832","layout":"IPY_MODEL_53b918c377ad477b8ba77d97170fbafc"}},"c1c9b7df18fb4727bad935f8fade2f18":{"model_name":"LayoutModel","model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","state":{}},"00f89eb2d2994d7fa5acc697adbcba44":{"model_name":"LayoutModel","model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","state":{"width":"20px"}},"4c2166c908de472a8bcee1852390074f":{"model_name":"ProgressStyleModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"description_width":""}},"c35aea41caeb46a5918f217b8311bcf9":{"model_name":"FloatProgressModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"value":1,"max":1,"bar_style":"success","style":"IPY_MODEL_dba6161cbfd144d98033bc38bf2af5a2","layout":"IPY_MODEL_7a3397b1c5ff405ba80625cd6c6cea6d"}},"dd616d1fe63e4c92b0dfb29168586786":{"model_name":"HTMLModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"value":"tokenizer_config.json: 100%","layout":"IPY_MODEL_a0bd2c40e64f49fbbb869689b37db685","style":"IPY_MODEL_73a48c0ce62d49c6b3d5db84acad5b38"}},"314e9715d6044be1ab5491276cacd2e0":{"model_name":"LayoutModel","model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","state":{}},"df33cbef64c64090b8d99512105a589c":{"model_name":"LayoutModel","model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","state":{}},"f1450996fc6f435d820f166ef866e83c":{"model_name":"LayoutModel","model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","state":{}},"ca6464de44ee4ddd9f51f6ed770895cb":{"model_name":"HBoxModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"children":["IPY_MODEL_c399919ef6c14daa9a6e386bf2d69631","IPY_MODEL_3616c7c73a8c44ba8b4190de8b133121","IPY_MODEL_c169d0acb4a24425a55590c1cdefd539"],"layout":"IPY_MODEL_94ebcdf3de874a218abad4b173504b84"}},"31c8d514f8b347e0ba606428430eb2c1":{"model_name":"HTMLStyleModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"description_width":"","font_size":null,"text_color":null}},"d4e57dc7818d42a6843ce746cefd7a04":{"model_name":"HTMLStyleModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"description_width":"","font_size":null,"text_color":null}},"9a99cd2b1ea449c7afa231d0be24b8d7":{"model_name":"HTMLStyleModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"description_width":"","font_size":null,"text_color":null}},"0197863977d941a8a50321cdfec5ef4f":{"model_name":"FloatProgressModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"value":21,"max":21,"bar_style":"success","style":"IPY_MODEL_dfddf78011ff4955a44835912c03b896","layout":"IPY_MODEL_ebbf1bc5804f4a4389945fdb75120195"}},"31949b6d2aa843e5bc260a12ec01736f":{"model_name":"HTMLModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"value":" 21/21 [00:03&lt;00:00,  4.89it/s]","layout":"IPY_MODEL_ca1ef48956444ce7920988aa2aa8fab1","style":"IPY_MODEL_32ac8a4493b74e9184ba44b0a48e896e"}},"ad3d6a8aac0f4067892851f3a6292792":{"model_name":"HTMLModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"value":"model.safetensors: 100%","layout":"IPY_MODEL_314e9715d6044be1ab5491276cacd2e0","style":"IPY_MODEL_a8a84727c0684af59e81ed77a4a8447d"}},"8c1a4cc6e6e342b99a9a25af6a0c6bb6":{"model_name":"HBoxModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"children":["IPY_MODEL_ad3d6a8aac0f4067892851f3a6292792","IPY_MODEL_f7c883301ef54f1ca2ded7a41145f83d","IPY_MODEL_76cd818d912d4e1e869d0a7d17c7fe02"],"layout":"IPY_MODEL_13d00f1ca31a43b18a0081d3ecc39855"}},"dfddf78011ff4955a44835912c03b896":{"model_name":"ProgressStyleModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"description_width":""}},"4dd2561c48044757b0ba64a42d819109":{"model_name":"LayoutModel","model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","state":{}},"d80daf127f0f43a1bbfc1f1e2c9e4557":{"model_name":"HTMLModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"value":" 232k/? [00:00&lt;00:00, 24.2MB/s]","layout":"IPY_MODEL_254e2ec765484abc96e5198c9886022e","style":"IPY_MODEL_37f6e5721f3a411782805a606ac67cce"}},"37f6e5721f3a411782805a606ac67cce":{"model_name":"HTMLStyleModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"description_width":"","font_size":null,"text_color":null}},"e4b72eecc4924d258545bceb33b3ca9e":{"model_name":"LayoutModel","model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","state":{}},"e6f2e84d3f274a1d8b7ae876d4939f1e":{"model_name":"ProgressStyleModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"description_width":""}},"3ac4c7217815479daf34ded8bb8e3384":{"model_name":"LayoutModel","model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","state":{}},"4261e304f5ff49e6962f904d6d20692d":{"model_name":"HBoxModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"children":["IPY_MODEL_43d73c14eb324ea0af245b0f99726b19","IPY_MODEL_de37781b5c5f45c68cbe9009e6dcb9e5","IPY_MODEL_2f53533b31384ba5bc996c0b0eaa3214"],"layout":"IPY_MODEL_df33cbef64c64090b8d99512105a589c"}},"a3563a8495594e9f975d0174b693d526":{"model_name":"HTMLModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"value":" 116/116 [00:00&lt;00:00, 14.4kB/s]","layout":"IPY_MODEL_6f5e61130a7143389c2113be04e68f90","style":"IPY_MODEL_bb4c83a5c3ef4780a1554ef5656fe49c"}},"f2aa5dd448b34024a05269724544bb89":{"model_name":"LayoutModel","model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","state":{}},"b6971e7e0f0c4f4d9299667d845260b4":{"model_name":"FloatProgressModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"value":612,"max":612,"bar_style":"success","style":"IPY_MODEL_75a03136f8f4411bb10c1d279f08d190","layout":"IPY_MODEL_d03576a2f3d548bebcd6167897eb0627"}},"9671b1259c2542dd80dc2973f049ef9e":{"model_name":"LayoutModel","model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","state":{}},"7c920ecabf12403495e2dcb983e69939":{"model_name":"HBoxModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"children":["IPY_MODEL_3f608c39ca0d4d0e9f5f9906bc658d54","IPY_MODEL_f1e8255043094197abcd0a531a6f822d","IPY_MODEL_1181017a5761408db9898ed0005461d3"],"layout":"IPY_MODEL_3ac4c7217815479daf34ded8bb8e3384"}},"0d14e1baaa3c4af2a79b88b4257ac5e5":{"model_name":"LayoutModel","model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","state":{}},"8c56b51115224c2bbcda76d0e03554c7":{"model_name":"HTMLModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"value":"README.md: ","layout":"IPY_MODEL_c0a2034062324c55bcbac9320df43834","style":"IPY_MODEL_647b7201388e4d328b1463fca5dd11ca"}},"a9d7c951d2424fa2988d41dc52967655":{"model_name":"LayoutModel","model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","state":{}},"d306fd6e7a5d4fb3a46e7de053d30fe7":{"model_name":"ProgressStyleModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"description_width":""}},"a0bd2c40e64f49fbbb869689b37db685":{"model_name":"LayoutModel","model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","state":{}},"c28ea8f2c4ee45fea157d6911c44bce4":{"model_name":"LayoutModel","model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","state":{}},"f25a0599009a413ab2390b194271c988":{"model_name":"HTMLStyleModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"description_width":"","font_size":null,"text_color":null}},"9259e4969c634fb285730e0079159c53":{"model_name":"HTMLStyleModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"description_width":"","font_size":null,"text_color":null}},"a0c4bf40a66d4debad69942dd7a5e91a":{"model_name":"HTMLStyleModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"description_width":"","font_size":null,"text_color":null}},"8f832dc8a3294c5e9c3a6a2565dbf93c":{"model_name":"LayoutModel","model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","state":{}},"480ff79fe5f04b509da95896b7ea7644":{"model_name":"HTMLStyleModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"description_width":"","font_size":null,"text_color":null}},"75a03136f8f4411bb10c1d279f08d190":{"model_name":"ProgressStyleModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"description_width":""}},"de37781b5c5f45c68cbe9009e6dcb9e5":{"model_name":"FloatProgressModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"value":1,"max":1,"bar_style":"success","style":"IPY_MODEL_11d7bca689184a8686161c3898a90c36","layout":"IPY_MODEL_00f89eb2d2994d7fa5acc697adbcba44"}},"220b646c834d4aafbb3893bb2b264897":{"model_name":"HBoxModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"children":["IPY_MODEL_38b94ff6aaf1471698cb1e9233b90bb1","IPY_MODEL_043cafbbc70240bfbd697833321fcd0c","IPY_MODEL_2f24d5c552e840048691c3a647453c22"],"layout":"IPY_MODEL_2ddf3b191bde454bbf79b51c6889ffea"}},"f54941287a094e4085b17342b6adeaba":{"model_name":"HTMLModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"value":"config_sentence_transformers.json: 100%","layout":"IPY_MODEL_527b65423cc84e28b338c47fe0a1be7b","style":"IPY_MODEL_9259e4969c634fb285730e0079159c53"}},"6d1772b6fabe4443b32a6f22723f069d":{"model_name":"LayoutModel","model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","state":{}},"3616c7c73a8c44ba8b4190de8b133121":{"model_name":"FloatProgressModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"value":53,"max":53,"bar_style":"success","style":"IPY_MODEL_17e9134bc8df466da55ea7be3a16d0e9","layout":"IPY_MODEL_136f71dd14044b76876975a96cf1d1ae"}},"c000951a67a0442ea80cd6e23bb3ecd1":{"model_name":"HBoxModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"children":["IPY_MODEL_6bfa3e8635cf4032a228921b9f8facbc","IPY_MODEL_d16146924d064f98993cb23d53e9e882","IPY_MODEL_31949b6d2aa843e5bc260a12ec01736f"],"layout":"IPY_MODEL_58d4fbff663b49fca7ec3e2e57c2e05c"}},"147e927919f44c5ea0b0c1e3cd92b608":{"model_name":"LayoutModel","model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","state":{}},"5e75466fc5844373a593542e27ccb2f8":{"model_name":"LayoutModel","model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","state":{}},"3aa08ab4daac49f5a44e2a3b00a459f3":{"model_name":"HBoxModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"children":["IPY_MODEL_50715882c8944411ab2c0fca8efd13fe","IPY_MODEL_b6971e7e0f0c4f4d9299667d845260b4","IPY_MODEL_8f745a01e2e04f298455c10575b91e91"],"layout":"IPY_MODEL_4dd2561c48044757b0ba64a42d819109"}},"52a1add3ff39487a8fd582ed62b84fac":{"model_name":"HTMLStyleModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"description_width":"","font_size":null,"text_color":null}},"8fd4d585d3524266ba51cdafd9e2f48c":{"model_name":"HTMLModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"value":" 21/21 [00:05&lt;00:00,  4.74it/s]","layout":"IPY_MODEL_e4b72eecc4924d258545bceb33b3ca9e","style":"IPY_MODEL_52a1add3ff39487a8fd582ed62b84fac"}},"2cf10712aedc421596039b175e632a97":{"model_name":"LayoutModel","model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","state":{"width":"20px"}},"185a4bc84fb6455ab4a43cc519c63847":{"model_name":"LayoutModel","model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","state":{}},"c828c8d58eb14ab8b5a76dd58edb5984":{"model_name":"HTMLModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"value":"special_tokens_map.json: 100%","layout":"IPY_MODEL_48e0ececab434025a9cff513821ef844","style":"IPY_MODEL_9f54f8f437f2416e9e4867aee7f32381"}},"dbfc801ea0444003aa271cd7f51d49d1":{"model_name":"HBoxModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"children":["IPY_MODEL_15ebe80fb078452e8952293d1854d3bd","IPY_MODEL_0197863977d941a8a50321cdfec5ef4f","IPY_MODEL_8fd4d585d3524266ba51cdafd9e2f48c"],"layout":"IPY_MODEL_6d1772b6fabe4443b32a6f22723f069d"}},"339131e52cec4029954f8798bb67ecc4":{"model_name":"LayoutModel","model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","state":{}},"6f5e61130a7143389c2113be04e68f90":{"model_name":"LayoutModel","model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","state":{}},"50715882c8944411ab2c0fca8efd13fe":{"model_name":"HTMLModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"value":"config.json: 100%","layout":"IPY_MODEL_9dcf3d620f494ee4be4b0017c5174cf1","style":"IPY_MODEL_d4e57dc7818d42a6843ce746cefd7a04"}},"38b94ff6aaf1471698cb1e9233b90bb1":{"model_name":"HTMLModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"value":"config.json: 100%","layout":"IPY_MODEL_c2107414d42341a793699e2c1a4e1acd","style":"IPY_MODEL_dbc37f24a77348efabfb266e21436cb0"}},"16e8aabed47d45428a42121b86d2b946":{"model_name":"LayoutModel","model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","state":{}},"379b4b98922c49e38f90944438dcc959":{"model_name":"HBoxModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"children":["IPY_MODEL_dd616d1fe63e4c92b0dfb29168586786","IPY_MODEL_72c8f7c0274c45549f05223f6455dc23","IPY_MODEL_9cafa6a3cd5f42879e56781ed4388f0b"],"layout":"IPY_MODEL_5e75466fc5844373a593542e27ccb2f8"}},"72e6aca9b42f4517a03feb4f35dcf6dd":{"model_name":"LayoutModel","model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","state":{}},"ca1ef48956444ce7920988aa2aa8fab1":{"model_name":"LayoutModel","model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","state":{}},"76cd818d912d4e1e869d0a7d17c7fe02":{"model_name":"HTMLModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"value":" 90.9M/90.9M [00:02&lt;00:00, 63.3MB/s]","layout":"IPY_MODEL_147e927919f44c5ea0b0c1e3cd92b608","style":"IPY_MODEL_65534339e7ad492fbc93462af84e075f"}},"6bfa3e8635cf4032a228921b9f8facbc":{"model_name":"HTMLModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"value":"Batches: 100%","layout":"IPY_MODEL_a9d7c951d2424fa2988d41dc52967655","style":"IPY_MODEL_cf0180147f4749e1ac71fe57fba93e30"}},"48e0ececab434025a9cff513821ef844":{"model_name":"LayoutModel","model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","state":{}},"2ddf3b191bde454bbf79b51c6889ffea":{"model_name":"LayoutModel","model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","state":{}},"9f54f8f437f2416e9e4867aee7f32381":{"model_name":"HTMLStyleModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"description_width":"","font_size":null,"text_color":null}},"c169d0acb4a24425a55590c1cdefd539":{"model_name":"HTMLModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"value":" 53.0/53.0 [00:00&lt;00:00, 9.08kB/s]","layout":"IPY_MODEL_ebbba4174f474d4bb1040bbafe45962b","style":"IPY_MODEL_9a99cd2b1ea449c7afa231d0be24b8d7"}},"8153721541e843c19cc80dd04ab72fc2":{"model_name":"HBoxModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"children":["IPY_MODEL_75e8293b50f14d91b8930ba1ed072f80","IPY_MODEL_c35aea41caeb46a5918f217b8311bcf9","IPY_MODEL_d80daf127f0f43a1bbfc1f1e2c9e4557"],"layout":"IPY_MODEL_f1450996fc6f435d820f166ef866e83c"}},"7a3397b1c5ff405ba80625cd6c6cea6d":{"model_name":"LayoutModel","model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","state":{"width":"20px"}},"65534339e7ad492fbc93462af84e075f":{"model_name":"HTMLStyleModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"description_width":"","font_size":null,"text_color":null}},"8065f94809b7433ba0626425f0e567b9":{"model_name":"FloatProgressModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"value":116,"max":116,"bar_style":"success","style":"IPY_MODEL_b68c753309c74eb2a8c6a47dbfe40497","layout":"IPY_MODEL_6a406b85b381469ebeae5ba8b694d6c3"}},"2f24d5c552e840048691c3a647453c22":{"model_name":"HTMLModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"value":" 190/190 [00:00&lt;00:00, 22.1kB/s]","layout":"IPY_MODEL_48231e3ea55948a68b419ad7788db873","style":"IPY_MODEL_6ce752d3cff74cca88a077c065f17baf"}},"8f745a01e2e04f298455c10575b91e91":{"model_name":"HTMLModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"value":" 612/612 [00:00&lt;00:00, 98.0kB/s]","layout":"IPY_MODEL_c1c9b7df18fb4727bad935f8fade2f18","style":"IPY_MODEL_41cae6989bc8484e85504d90856c7c6d"}},"8560787258074f95ba1ebc13b8ee74af":{"model_name":"LayoutModel","model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","state":{}},"75e8293b50f14d91b8930ba1ed072f80":{"model_name":"HTMLModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"value":"vocab.txt: ","layout":"IPY_MODEL_8560787258074f95ba1ebc13b8ee74af","style":"IPY_MODEL_31c8d514f8b347e0ba606428430eb2c1"}},"5826f402a0ff4b77880c631847df2fb7":{"model_name":"LayoutModel","model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","state":{}},"15ebe80fb078452e8952293d1854d3bd":{"model_name":"HTMLModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"value":"Batches: 100%","layout":"IPY_MODEL_339131e52cec4029954f8798bb67ecc4","style":"IPY_MODEL_62c03c8cc1af4fd6ac69f4a391effe05"}},"94ebcdf3de874a218abad4b173504b84":{"model_name":"LayoutModel","model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","state":{}},"ebbba4174f474d4bb1040bbafe45962b":{"model_name":"LayoutModel","model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","state":{}},"4631b3607cb3488fa4e4509fd9c3fce9":{"model_name":"LayoutModel","model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","state":{}},"d16146924d064f98993cb23d53e9e882":{"model_name":"FloatProgressModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"value":21,"max":21,"bar_style":"success","style":"IPY_MODEL_f99d2065eb584cdda82b2e830d2bc16f","layout":"IPY_MODEL_12244a5eca40475785b8a4da4d68bff1"}},"b68c753309c74eb2a8c6a47dbfe40497":{"model_name":"ProgressStyleModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"description_width":""}},"43d73c14eb324ea0af245b0f99726b19":{"model_name":"HTMLModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"value":"tokenizer.json: ","layout":"IPY_MODEL_16e8aabed47d45428a42121b86d2b946","style":"IPY_MODEL_0437f0a73f9249ae83c8aa166ac6312a"}},"2f53533b31384ba5bc996c0b0eaa3214":{"model_name":"HTMLModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"value":" 466k/? [00:00&lt;00:00, 36.4MB/s]","layout":"IPY_MODEL_5410e2503bc6435295d2738226c8d96e","style":"IPY_MODEL_fcb7b955bf46416cb979e3b3b4ab0b8c"}},"32ac8a4493b74e9184ba44b0a48e896e":{"model_name":"HTMLStyleModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"description_width":"","font_size":null,"text_color":null}},"73a48c0ce62d49c6b3d5db84acad5b38":{"model_name":"HTMLStyleModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"description_width":"","font_size":null,"text_color":null}},"9cafa6a3cd5f42879e56781ed4388f0b":{"model_name":"HTMLModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"value":" 350/350 [00:00&lt;00:00, 47.3kB/s]","layout":"IPY_MODEL_ad0201490828499faa4b90015b9d6c7e","style":"IPY_MODEL_f25a0599009a413ab2390b194271c988"}},"12bf441026404434b7d4b084ed26c4b6":{"model_name":"LayoutModel","model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","state":{}},"3b179caf59294eb8af0811e157dc73f6":{"model_name":"ProgressStyleModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"description_width":""}},"f1e8255043094197abcd0a531a6f822d":{"model_name":"FloatProgressModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"value":349,"max":349,"bar_style":"success","style":"IPY_MODEL_3b179caf59294eb8af0811e157dc73f6","layout":"IPY_MODEL_e378e34bb7b2453da8fe1fd3b3408551"}},"a8a84727c0684af59e81ed77a4a8447d":{"model_name":"HTMLStyleModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"description_width":"","font_size":null,"text_color":null}},"6fddce0423bb4e339fb3fde5f1d0a1de":{"model_name":"HTMLStyleModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"description_width":"","font_size":null,"text_color":null}},"0437f0a73f9249ae83c8aa166ac6312a":{"model_name":"HTMLStyleModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"description_width":"","font_size":null,"text_color":null}},"a9c123945aae4ae090293701c00dde3a":{"model_name":"ProgressStyleModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"description_width":""}},"62c03c8cc1af4fd6ac69f4a391effe05":{"model_name":"HTMLStyleModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"description_width":"","font_size":null,"text_color":null}},"48231e3ea55948a68b419ad7788db873":{"model_name":"LayoutModel","model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","state":{}},"043cafbbc70240bfbd697833321fcd0c":{"model_name":"FloatProgressModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"value":190,"max":190,"bar_style":"success","style":"IPY_MODEL_a9c123945aae4ae090293701c00dde3a","layout":"IPY_MODEL_9671b1259c2542dd80dc2973f049ef9e"}},"49efba11652647ab85d7bdab84984910":{"model_name":"HTMLModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"value":" 10.5k/? [00:00&lt;00:00, 1.35MB/s]","layout":"IPY_MODEL_c05d9f015813442980981b344b9a776d","style":"IPY_MODEL_9206ad36106245bba4855e635d2f2134"}},"c2107414d42341a793699e2c1a4e1acd":{"model_name":"LayoutModel","model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","state":{}},"254e2ec765484abc96e5198c9886022e":{"model_name":"LayoutModel","model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","state":{}},"57e8516f2c254cc5b6faf684db83a269":{"model_name":"HBoxModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"children":["IPY_MODEL_f54941287a094e4085b17342b6adeaba","IPY_MODEL_8065f94809b7433ba0626425f0e567b9","IPY_MODEL_a3563a8495594e9f975d0174b693d526"],"layout":"IPY_MODEL_5826f402a0ff4b77880c631847df2fb7"}},"ea7de4ba61d64e1f8c750e23bff11ab8":{"model_name":"FloatProgressModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"value":1,"max":1,"bar_style":"success","style":"IPY_MODEL_e6f2e84d3f274a1d8b7ae876d4939f1e","layout":"IPY_MODEL_2cf10712aedc421596039b175e632a97"}},"647b7201388e4d328b1463fca5dd11ca":{"model_name":"HTMLStyleModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"description_width":"","font_size":null,"text_color":null}},"9dcf3d620f494ee4be4b0017c5174cf1":{"model_name":"LayoutModel","model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","state":{}},"dbc37f24a77348efabfb266e21436cb0":{"model_name":"HTMLStyleModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"description_width":"","font_size":null,"text_color":null}}}}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"known_lakehouses":[{"id":"06b86e1a-668d-4d65-a5f0-7ba8a61fa57d"}],"default_lakehouse":"06b86e1a-668d-4d65-a5f0-7ba8a61fa57d","default_lakehouse_name":"ParkingDataLakehouse","default_lakehouse_workspace_id":"d3afc09a-dc29-418e-be57-836e9d2cc5f1"}}},"nbformat":4,"nbformat_minor":5}
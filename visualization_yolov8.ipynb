{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca879362-690b-4846-bca4-28a7c4a0bfb1",
   "metadata": {
    "advisor": {
     "adviceMetadata": "{\"artifactId\":\"be7e8010-fe91-4fef-bad3-16b3209ce53f\",\"activityId\":\"ac1fa5d8-b91e-4017-b0fa-f58a05e0ce1c\",\"applicationId\":\"application_1760119365461_0001\",\"jobGroupId\":\"8\",\"advices\":{\"error\":1}}"
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Parking data saved to data/parking_zones.json\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Paths\n",
    "image_path = \"data/x.png\"\n",
    "output_dir = \"data\"\n",
    "output_json = os.path.join(output_dir, \"parking_zones.json\")\n",
    "\n",
    "# Create data directory if not exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Load image\n",
    "image = cv2.imread(image_path)\n",
    "output = image.copy()\n",
    "\n",
    "# Convert to grayscale\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Blur and edge detection\n",
    "blur = cv2.GaussianBlur(gray, (5,5), 0)\n",
    "edges = cv2.Canny(blur, 50, 150)\n",
    "\n",
    "# Find contours (potential parking slots)\n",
    "contours, _ = cv2.findContours(edges, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "parking_zones = []\n",
    "zone_id = 1\n",
    "\n",
    "for cnt in contours:\n",
    "    x, y, w, h = cv2.boundingRect(cnt)\n",
    "\n",
    "    # Filter small or large areas\n",
    "    if 40 < w < 150 and 80 < h < 200:\n",
    "        roi = gray[y:y+h, x:x+w]\n",
    "        mean_val = np.mean(roi)\n",
    "\n",
    "        # Assume lighter areas mean free space\n",
    "        status = \"free\" if mean_val > 100 else \"occupied\"\n",
    "\n",
    "        parking_zones.append({\n",
    "            \"zone_id\": f\"A{zone_id}\",\n",
    "            \"coordinates\": {\"x1\": int(x), \"y1\": int(y), \"x2\": int(x+w), \"y2\": int(y+h)},\n",
    "            \"status\": status\n",
    "        })\n",
    "        zone_id += 1\n",
    "\n",
    "# Save JSON to data/ folder\n",
    "with open(output_json, \"w\") as f:\n",
    "    json.dump({\"parking_zones\": parking_zones}, f, indent=2)\n",
    "\n",
    "print(f\"‚úÖ Parking data saved to {output_json}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca90d8ef-0164-427f-a9f2-f389cfc2790f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üé• STEP 4: VISUAL AI DEMO ‚Äì YOLOv8 PARKING MANAGEMENT VISUALIZATION\n",
      "üöó Processing video frames for parking visualization...\n",
      "üß© Processed 50 frames...\n",
      "üß© Processed 100 frames...\n",
      "üß© Processed 150 frames...\n",
      "üß© Processed 200 frames...\n",
      "‚úÖ Visualization complete ‚Äî saved to data/parking_visual.mp4\n",
      "üñºÔ∏è Processed 206 frames in 51s\n",
      "üìä Final Occupancy Rate: 0.0% (0/9 occupied)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# STEP 4: VISUAL AI DEMO ‚Äì YOLOv8 PARKING MANAGEMENT VISUALIZATION (FIXED)\n",
    "# =============================================================================\n",
    "\n",
    "# !pip install ultralytics opencv-python numpy\n",
    "\n",
    "print(\"\\nüé• STEP 4: VISUAL AI DEMO ‚Äì YOLOv8 PARKING MANAGEMENT VISUALIZATION\")\n",
    "\n",
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "\n",
    "class ParkingVisualizer:\n",
    "    def __init__(self, model_path, region_json, video_path, output_path):\n",
    "        \"\"\"\n",
    "        YOLOv8-based Parking Visualization System\n",
    "        \"\"\"\n",
    "        self.model = YOLO(model_path)\n",
    "        self.video_path = video_path\n",
    "        self.output_path = output_path\n",
    "\n",
    "        with open(region_json, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        # Accept both \"parking_zones\" key or direct list\n",
    "        self.regions = data[\"parking_zones\"] if isinstance(data, dict) and \"parking_zones\" in data else data\n",
    "\n",
    "        self.colors = {\n",
    "            \"occupied\": (0, 0, 255),  # Red\n",
    "            \"available\": (0, 255, 0),  # Green\n",
    "        }\n",
    "\n",
    "    def is_inside_region(self, point, polygon):\n",
    "        \"\"\"Check if a detected object's center point lies inside a polygon region.\"\"\"\n",
    "        return cv2.pointPolygonTest(np.array(polygon, np.int32), point, False) >= 0\n",
    "\n",
    "    def run(self, show_live=False):\n",
    "        \"\"\"Run visualization process.\"\"\"\n",
    "        cap = cv2.VideoCapture(self.video_path)\n",
    "        if not cap.isOpened():\n",
    "            print(\"‚ùå Error: Unable to open video file.\")\n",
    "            return\n",
    "\n",
    "        frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "        os.makedirs(os.path.dirname(self.output_path), exist_ok=True)\n",
    "        out = cv2.VideoWriter(\n",
    "            self.output_path,\n",
    "            cv2.VideoWriter_fourcc(*\"mp4v\"),\n",
    "            fps,\n",
    "            (frame_width, frame_height),\n",
    "        )\n",
    "\n",
    "        print(\"üöó Processing video frames for parking visualization...\")\n",
    "        frame_count = 0\n",
    "        total_spots = len(self.regions)\n",
    "        start_time = datetime.now()\n",
    "\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            detections = self.model(frame, verbose=False)\n",
    "            boxes = detections[0].boxes.xyxy.cpu().numpy() if detections and detections[0].boxes else []\n",
    "\n",
    "            region_status = {str(i): \"available\" for i in range(len(self.regions))}\n",
    "\n",
    "            for box in boxes:\n",
    "                x1, y1, x2, y2 = map(int, box[:4])\n",
    "                cx, cy = int((x1 + x2) / 2), int((y1 + y2) / 2)\n",
    "\n",
    "                for i, region in enumerate(self.regions):\n",
    "                    # Handle both \"points\" and \"coordinates\" formats\n",
    "                    if \"points\" in region:\n",
    "                        polygon = region[\"points\"]\n",
    "                    elif \"coordinates\" in region:\n",
    "                        c = region[\"coordinates\"]\n",
    "                        polygon = [\n",
    "                            [c[\"x1\"], c[\"y1\"]],\n",
    "                            [c[\"x2\"], c[\"y1\"]],\n",
    "                            [c[\"x2\"], c[\"y2\"]],\n",
    "                            [c[\"x1\"], c[\"y2\"]],\n",
    "                        ]\n",
    "                    else:\n",
    "                        continue\n",
    "\n",
    "                    if self.is_inside_region((cx, cy), polygon):\n",
    "                        region_status[str(i)] = \"occupied\"\n",
    "\n",
    "            occupied = list(region_status.values()).count(\"occupied\")\n",
    "            available = total_spots - occupied\n",
    "            occupancy_rate = (occupied / total_spots) * 100 if total_spots > 0 else 0\n",
    "\n",
    "            # Draw all regions\n",
    "            for i, region in enumerate(self.regions):\n",
    "                if \"points\" in region:\n",
    "                    pts = np.array(region[\"points\"], np.int32)\n",
    "                elif \"coordinates\" in region:\n",
    "                    c = region[\"coordinates\"]\n",
    "                    pts = np.array(\n",
    "                        [\n",
    "                            [c[\"x1\"], c[\"y1\"]],\n",
    "                            [c[\"x2\"], c[\"y1\"]],\n",
    "                            [c[\"x2\"], c[\"y2\"]],\n",
    "                            [c[\"x1\"], c[\"y2\"]],\n",
    "                        ],\n",
    "                        np.int32,\n",
    "                    )\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "                status = region_status[str(i)]\n",
    "                color = self.colors[status]\n",
    "                cv2.polylines(frame, [pts], True, color, 2)\n",
    "                cv2.putText(\n",
    "                    frame,\n",
    "                    status.upper(),\n",
    "                    (pts[0][0], pts[0][1] - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.6,\n",
    "                    color,\n",
    "                    2,\n",
    "                )\n",
    "\n",
    "            # Draw info box\n",
    "            cv2.rectangle(frame, (10, 10), (380, 80), (50, 50, 50), -1)\n",
    "            cv2.putText(\n",
    "                frame,\n",
    "                f\"Total Spots: {total_spots}\",\n",
    "                (20, 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.6,\n",
    "                (255, 255, 255),\n",
    "                2,\n",
    "            )\n",
    "            cv2.putText(\n",
    "                frame,\n",
    "                f\"Available: {available}  Occupied: {occupied}\",\n",
    "                (20, 50),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.6,\n",
    "                (0, 255, 255),\n",
    "                2,\n",
    "            )\n",
    "            cv2.putText(\n",
    "                frame,\n",
    "                f\"Occupancy: {occupancy_rate:.1f}%\",\n",
    "                (200, 70),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.6,\n",
    "                (255, 255, 255),\n",
    "                2,\n",
    "            )\n",
    "\n",
    "            out.write(frame)\n",
    "            frame_count += 1\n",
    "\n",
    "            if show_live:\n",
    "                try:\n",
    "                    cv2.imshow(\"Smart Parking Visualization\", frame)\n",
    "                    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "                        break\n",
    "                except cv2.error:\n",
    "                    print(\"‚ö†Ô∏è GUI not supported ‚Äî skipping live display.\")\n",
    "                    show_live = False\n",
    "\n",
    "            if frame_count % 50 == 0:\n",
    "                print(f\"üß© Processed {frame_count} frames...\")\n",
    "\n",
    "        cap.release()\n",
    "        out.release()\n",
    "\n",
    "        if show_live:\n",
    "            try:\n",
    "                cv2.destroyAllWindows()\n",
    "            except cv2.error:\n",
    "                print(\"‚ö†Ô∏è GUI not supported ‚Äî skipping window cleanup.\")\n",
    "\n",
    "        duration = (datetime.now() - start_time).seconds\n",
    "        print(f\"‚úÖ Visualization complete ‚Äî saved to {self.output_path}\")\n",
    "        print(f\"üñºÔ∏è Processed {frame_count} frames in {duration}s\")\n",
    "        print(f\"üìä Final Occupancy Rate: {occupancy_rate:.1f}% ({occupied}/{total_spots} occupied)\")\n",
    "# =============================================================================\n",
    "# Example Usage\n",
    "# =============================================================================\n",
    "\n",
    "model_path = \"models/yolov8n.pt\"\n",
    "region_json = \"data/parking_zones.json\"\n",
    "video_path = \"data/sample_video.mp4\"\n",
    "output_path = \"data/parking_visual.mp4\"  # ‚úÖ save in data/\n",
    "\n",
    "visualizer = ParkingVisualizer(model_path, region_json, video_path, output_path)\n",
    "visualizer.run(show_live=False)  # ‚úÖ Set to True only if your environment supports OpenCV windows"
   ]
  }
 ],
 "metadata": {
  "dependencies": {},
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "microsoft": {
   "language": "python",
   "language_group": "synapse_pyspark",
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "spark_compute": {
   "compute_id": "/trident/default",
   "session_options": {
    "conf": {
     "spark.synapse.nbs.session.timeout": "1200000"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

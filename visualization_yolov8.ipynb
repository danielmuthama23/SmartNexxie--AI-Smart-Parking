{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca879362-690b-4846-bca4-28a7c4a0bfb1",
   "metadata": {
    "advisor": {
     "adviceMetadata": "{\"artifactId\":\"be7e8010-fe91-4fef-bad3-16b3209ce53f\",\"activityId\":\"ac1fa5d8-b91e-4017-b0fa-f58a05e0ce1c\",\"applicationId\":\"application_1760119365461_0001\",\"jobGroupId\":\"8\",\"advices\":{\"error\":1}}"
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Parking data saved to data/parking_zones.json\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Paths\n",
    "image_path = \"data/x.png\"\n",
    "output_dir = \"data\"\n",
    "output_json = os.path.join(output_dir, \"parking_zones.json\")\n",
    "\n",
    "# Create data directory if not exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Load image\n",
    "image = cv2.imread(image_path)\n",
    "output = image.copy()\n",
    "\n",
    "# Convert to grayscale\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Blur and edge detection\n",
    "blur = cv2.GaussianBlur(gray, (5,5), 0)\n",
    "edges = cv2.Canny(blur, 50, 150)\n",
    "\n",
    "# Find contours (potential parking slots)\n",
    "contours, _ = cv2.findContours(edges, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "parking_zones = []\n",
    "zone_id = 1\n",
    "\n",
    "for cnt in contours:\n",
    "    x, y, w, h = cv2.boundingRect(cnt)\n",
    "\n",
    "    # Filter small or large areas\n",
    "    if 40 < w < 150 and 80 < h < 200:\n",
    "        roi = gray[y:y+h, x:x+w]\n",
    "        mean_val = np.mean(roi)\n",
    "\n",
    "        # Assume lighter areas mean free space\n",
    "        status = \"free\" if mean_val > 100 else \"occupied\"\n",
    "\n",
    "        parking_zones.append({\n",
    "            \"zone_id\": f\"A{zone_id}\",\n",
    "            \"coordinates\": {\"x1\": int(x), \"y1\": int(y), \"x2\": int(x+w), \"y2\": int(y+h)},\n",
    "            \"status\": status\n",
    "        })\n",
    "        zone_id += 1\n",
    "\n",
    "# Save JSON to data/ folder\n",
    "with open(output_json, \"w\") as f:\n",
    "    json.dump({\"parking_zones\": parking_zones}, f, indent=2)\n",
    "\n",
    "print(f\"✅ Parking data saved to {output_json}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca90d8ef-0164-427f-a9f2-f389cfc2790f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎥 STEP 4: VISUAL AI DEMO – YOLOv8 PARKING MANAGEMENT VISUALIZATION\n",
      "🚗 Processing video frames for parking visualization...\n",
      "🧩 Processed 50 frames...\n",
      "🧩 Processed 100 frames...\n",
      "🧩 Processed 150 frames...\n",
      "🧩 Processed 200 frames...\n",
      "✅ Visualization complete — saved to data/parking_visual.mp4\n",
      "🖼️ Processed 206 frames in 51s\n",
      "📊 Final Occupancy Rate: 0.0% (0/9 occupied)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# STEP 4: VISUAL AI DEMO – YOLOv8 PARKING MANAGEMENT VISUALIZATION (FIXED)\n",
    "# =============================================================================\n",
    "\n",
    "# !pip install ultralytics opencv-python numpy\n",
    "\n",
    "print(\"\\n🎥 STEP 4: VISUAL AI DEMO – YOLOv8 PARKING MANAGEMENT VISUALIZATION\")\n",
    "\n",
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "\n",
    "class ParkingVisualizer:\n",
    "    def __init__(self, model_path, region_json, video_path, output_path):\n",
    "        \"\"\"\n",
    "        YOLOv8-based Parking Visualization System\n",
    "        \"\"\"\n",
    "        self.model = YOLO(model_path)\n",
    "        self.video_path = video_path\n",
    "        self.output_path = output_path\n",
    "\n",
    "        with open(region_json, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        # Accept both \"parking_zones\" key or direct list\n",
    "        self.regions = data[\"parking_zones\"] if isinstance(data, dict) and \"parking_zones\" in data else data\n",
    "\n",
    "        self.colors = {\n",
    "            \"occupied\": (0, 0, 255),  # Red\n",
    "            \"available\": (0, 255, 0),  # Green\n",
    "        }\n",
    "\n",
    "    def is_inside_region(self, point, polygon):\n",
    "        \"\"\"Check if a detected object's center point lies inside a polygon region.\"\"\"\n",
    "        return cv2.pointPolygonTest(np.array(polygon, np.int32), point, False) >= 0\n",
    "\n",
    "    def run(self, show_live=False):\n",
    "        \"\"\"Run visualization process.\"\"\"\n",
    "        cap = cv2.VideoCapture(self.video_path)\n",
    "        if not cap.isOpened():\n",
    "            print(\"❌ Error: Unable to open video file.\")\n",
    "            return\n",
    "\n",
    "        frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "        os.makedirs(os.path.dirname(self.output_path), exist_ok=True)\n",
    "        out = cv2.VideoWriter(\n",
    "            self.output_path,\n",
    "            cv2.VideoWriter_fourcc(*\"mp4v\"),\n",
    "            fps,\n",
    "            (frame_width, frame_height),\n",
    "        )\n",
    "\n",
    "        print(\"🚗 Processing video frames for parking visualization...\")\n",
    "        frame_count = 0\n",
    "        total_spots = len(self.regions)\n",
    "        start_time = datetime.now()\n",
    "\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            detections = self.model(frame, verbose=False)\n",
    "            boxes = detections[0].boxes.xyxy.cpu().numpy() if detections and detections[0].boxes else []\n",
    "\n",
    "            region_status = {str(i): \"available\" for i in range(len(self.regions))}\n",
    "\n",
    "            for box in boxes:\n",
    "                x1, y1, x2, y2 = map(int, box[:4])\n",
    "                cx, cy = int((x1 + x2) / 2), int((y1 + y2) / 2)\n",
    "\n",
    "                for i, region in enumerate(self.regions):\n",
    "                    # Handle both \"points\" and \"coordinates\" formats\n",
    "                    if \"points\" in region:\n",
    "                        polygon = region[\"points\"]\n",
    "                    elif \"coordinates\" in region:\n",
    "                        c = region[\"coordinates\"]\n",
    "                        polygon = [\n",
    "                            [c[\"x1\"], c[\"y1\"]],\n",
    "                            [c[\"x2\"], c[\"y1\"]],\n",
    "                            [c[\"x2\"], c[\"y2\"]],\n",
    "                            [c[\"x1\"], c[\"y2\"]],\n",
    "                        ]\n",
    "                    else:\n",
    "                        continue\n",
    "\n",
    "                    if self.is_inside_region((cx, cy), polygon):\n",
    "                        region_status[str(i)] = \"occupied\"\n",
    "\n",
    "            occupied = list(region_status.values()).count(\"occupied\")\n",
    "            available = total_spots - occupied\n",
    "            occupancy_rate = (occupied / total_spots) * 100 if total_spots > 0 else 0\n",
    "\n",
    "            # Draw all regions\n",
    "            for i, region in enumerate(self.regions):\n",
    "                if \"points\" in region:\n",
    "                    pts = np.array(region[\"points\"], np.int32)\n",
    "                elif \"coordinates\" in region:\n",
    "                    c = region[\"coordinates\"]\n",
    "                    pts = np.array(\n",
    "                        [\n",
    "                            [c[\"x1\"], c[\"y1\"]],\n",
    "                            [c[\"x2\"], c[\"y1\"]],\n",
    "                            [c[\"x2\"], c[\"y2\"]],\n",
    "                            [c[\"x1\"], c[\"y2\"]],\n",
    "                        ],\n",
    "                        np.int32,\n",
    "                    )\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "                status = region_status[str(i)]\n",
    "                color = self.colors[status]\n",
    "                cv2.polylines(frame, [pts], True, color, 2)\n",
    "                cv2.putText(\n",
    "                    frame,\n",
    "                    status.upper(),\n",
    "                    (pts[0][0], pts[0][1] - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.6,\n",
    "                    color,\n",
    "                    2,\n",
    "                )\n",
    "\n",
    "            # Draw info box\n",
    "            cv2.rectangle(frame, (10, 10), (380, 80), (50, 50, 50), -1)\n",
    "            cv2.putText(\n",
    "                frame,\n",
    "                f\"Total Spots: {total_spots}\",\n",
    "                (20, 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.6,\n",
    "                (255, 255, 255),\n",
    "                2,\n",
    "            )\n",
    "            cv2.putText(\n",
    "                frame,\n",
    "                f\"Available: {available}  Occupied: {occupied}\",\n",
    "                (20, 50),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.6,\n",
    "                (0, 255, 255),\n",
    "                2,\n",
    "            )\n",
    "            cv2.putText(\n",
    "                frame,\n",
    "                f\"Occupancy: {occupancy_rate:.1f}%\",\n",
    "                (200, 70),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.6,\n",
    "                (255, 255, 255),\n",
    "                2,\n",
    "            )\n",
    "\n",
    "            out.write(frame)\n",
    "            frame_count += 1\n",
    "\n",
    "            if show_live:\n",
    "                try:\n",
    "                    cv2.imshow(\"Smart Parking Visualization\", frame)\n",
    "                    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "                        break\n",
    "                except cv2.error:\n",
    "                    print(\"⚠️ GUI not supported — skipping live display.\")\n",
    "                    show_live = False\n",
    "\n",
    "            if frame_count % 50 == 0:\n",
    "                print(f\"🧩 Processed {frame_count} frames...\")\n",
    "\n",
    "        cap.release()\n",
    "        out.release()\n",
    "\n",
    "        if show_live:\n",
    "            try:\n",
    "                cv2.destroyAllWindows()\n",
    "            except cv2.error:\n",
    "                print(\"⚠️ GUI not supported — skipping window cleanup.\")\n",
    "\n",
    "        duration = (datetime.now() - start_time).seconds\n",
    "        print(f\"✅ Visualization complete — saved to {self.output_path}\")\n",
    "        print(f\"🖼️ Processed {frame_count} frames in {duration}s\")\n",
    "        print(f\"📊 Final Occupancy Rate: {occupancy_rate:.1f}% ({occupied}/{total_spots} occupied)\")\n",
    "# =============================================================================\n",
    "# Example Usage\n",
    "# =============================================================================\n",
    "\n",
    "model_path = \"models/yolov8n.pt\"\n",
    "region_json = \"data/parking_zones.json\"\n",
    "video_path = \"data/sample_video.mp4\"\n",
    "output_path = \"data/parking_visual.mp4\"  # ✅ save in data/\n",
    "\n",
    "visualizer = ParkingVisualizer(model_path, region_json, video_path, output_path)\n",
    "visualizer.run(show_live=False)  # ✅ Set to True only if your environment supports OpenCV windows"
   ]
  }
 ],
 "metadata": {
  "dependencies": {},
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "microsoft": {
   "language": "python",
   "language_group": "synapse_pyspark",
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "spark_compute": {
   "compute_id": "/trident/default",
   "session_options": {
    "conf": {
     "spark.synapse.nbs.session.timeout": "1200000"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
